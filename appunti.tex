\documentclass[a4paper,11pt]{report}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{listings}

\title{Dependable Distributed Systems}
\author{Ida Francesca Benvenuto}
\date{november-december 2025}

\begin{document}

\maketitle
\chapter{Time in Distributed System(4)}

\section{Introduction}

In a distributed system, many processes run on different computers that are connected by a network. These processes need to work together to complete computations, and they can only communicate by sending messages to each other. 

Many applications need to order events correctly and synchronize processes to work properly. Examples include air traffic control, network monitoring, and financial systems where we need to track when orders are made and executed. This is why \textbf{time is very important in distributed systems}.

\section{Why is Time Important?}

Time is a quantity that we want to measure and understand. Many algorithms depend on time to work correctly:

\begin{itemize}
\item \textbf{Data consistency}: When we have copies of data stored in multiple places, we need to make sure all copies show the same information at the same time.
\item \textbf{Authentication}: We need to know when messages were sent to prevent security problems.
\item \textbf{Double processing avoidance}: We must not process the same request twice by accident.
\end{itemize}

To solve these problems, we need to be able to put events in the correct order. This means we need to understand and order events that happen in different places at almost the same time.

\section{Why is Using Time Difficult in Distributed Systems?}

The main problem is that we need all processes to agree on what time it is. It is easy to order events that happen in the same process because they happen one after another. However, when events happen in different processes at about the same time, we cannot easily know which event happened first. 

In a distributed system with network delays and processing delays, it is impossible to have one clock that all processes share. Each process has its own local clock, and these clocks will show different times.

\section{System Model}

A distributed system is made up of a set of processes \(P = \{p_1, p_2, \ldots, p_n\}\). Each process runs on a single computer with no shared memory. Each process \(p_i\) has a state \(s_i\) that changes as the process executes.

Processes can only communicate by exchanging messages through the network. They cannot access other processes' memory directly.

\section{Events and Computation}

Each process creates a sequence of events during its execution:

\begin{itemize}
\item \textbf{Internal events}: Events that change the process state (for example, calculating something).
\item \textbf{External events}: Events where the process sends or receives a message.
\end{itemize}

We use the notation \(e_i^k\) to mean the $k$-th event created by process \(p_i\). 
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-04 alle 17.01.16.png}
\end{figure}
\subsection{Ordering Events}

For events that happen in the same process, we can order them easily. We write \(e \rightarrow_i e'\) if event \(e\) happens before event \(e'\) in process \(p_i\).

The \textbf{local history} of a process is the sequence of all events that it creates. For process \(p_1\), the local history might be:
\[
\text{history}(p_1) = h_1 = e_1^1, e_1^2, e_1^3, e_1^4, e_1^5, e_1^6
\]
the \textbf{partial local history} is the sequence of events that a process has created so far, which can be different for each process.

When processes communicate, they send messages to each other. We write \(e \rightarrow e'\) if event \(e\) happens before event \(e'\) in the global history of the system.

The \textbf{global history} is the collection of all local histories from all processes in the system.

\section{Timestamping and Physical Clocks}

One way to solve the ordering problem is to attach a label (called a \textbf{timestamp}) to each event. If we give each event a number that represents when it happened, we can order events from different processes.

A simple idea is to have each process put a timestamp on its events using its local hardware clock. However, this does not always work well because:

\begin{enumerate}
\item Hardware clocks are not perfectly accurate.
\item Different computers' clocks show different times.
\item Clocks drift (they gradually move away from the correct time).
\end{enumerate}

\section{Physical Computer Clocks}

Each computer has a \textbf{hardware clock} made of an oscillator (something that vibrates at a regular speed) and a counter that increases by one for each vibration. The operating system reads this hardware clock and creates a \textbf{software clock}.

The software clock \(C_i(t)\) for process \(p_i\) at real time $t$ is:
\[
C_i(t) = H_i(t) + \text{offset}
\]

where \(H_i(t)\) is the hardware clock value and offset is a correction value.

\subsection{Clock Accuracy}

The software clock \(C_i(t)\) is an approximation of the real time $t$. However, it is not perfect:

\begin{itemize}
\item It can be different from the real time.
\item Different processes may have different values because hardware is not identical.
\end{itemize}

In practice, a 64-bit software clock might show time in nanoseconds (very small units of time).

\subsection{Clock Resolution}

An important question is: How small must the time step be between updates so we can tell two events apart? The resolution must be smaller than the time between two important events.

\section{Problems with Clock Synchronization}

Two important measurements describe how well clocks stay synchronized:

\begin{itemize}
\item \textbf{Skew}: The difference between two clocks at the same time: \(|C_i(t) - C_j(t)|\). This is how much two clocks disagree with each other.
\item \textbf{Drift rate}: How fast a clock moves away from the correct time. It is measured as change per second. For example, a drift rate of 2 microseconds per second means a clock increases by 1 second + 2 microseconds for each real second that passes.
\end{itemize}

Regular quartz clocks (the type in most computers) drift by about 1 second in 11 to 12 days, which is a drift rate of about \(10^{-6}\) seconds per second. Better quality quartz clocks have a drift rate of \(10^{-7}\) to \(10^{-8}\) seconds per second. Only atomic clocks (based on atomic oscillators) can achieve very small drift rates of \(10^{-13}\) seconds per second.

\section{Universal Time Coordinated (UTC)}

\textbf{UTC} (Universal Time Coordinated) is an international standard for measuring time. It is based on International Atomic Time, which is defined by how long it takes a cesium atom to complete a certain number of state transitions.

When we say 1 second, we mean the time for a cesium atom to make 9,192,631,770 state transitions.

UTC is the time standard used worldwide, and it is available from specialized time sources called UTC sources.

\section{Internal and External Synchronization}

We need to understand two types of clock synchronization:

\subsection{External Synchronization}

In external synchronization, all processes synchronize their clocks with an external time source \(S\) (a UTC source).

We say that clocks \(C_i\) are \textbf{externally synchronized} with accuracy \(D > 0\) if, for all processes \(i = 1, 2, \ldots, N\) and for all real times $t$ in some time interval:
\[
|S(t) - C_i(t)| < D
\]

This means each local clock differs from the external time source by less than \(D\).

\subsection{Internal Synchronization}

In internal synchronization, all processes synchronize their clocks with each other, not necessarily with an external source.

We say that clocks are \textbf{internally synchronized} with accuracy \(D > 0\) if, for all pairs of processes \(i, j = 1, 2, \ldots, N\) and for all real times $t$ in some time interval:
\[
|C_i(t) - C_j(t)| < D
\]

This means all local clocks agree with each other within accuracy \(D\).

\subsection{Relationship Between Internal and External Synchronization}

Important note: Clocks that are internally synchronized are not necessarily externally synchronized. Even if all clocks agree with each other, they might all be wrong compared to UTC!

However, if a set of processes is externally synchronized with accuracy \(D\), then it is also internally synchronized with accuracy \(2D\).

\section{Correct Clocks}

A hardware clock \(H\) is called a \textbf{correct clock} if its drift rate stays within a limited bound. We write this as:
\[
1 - \rho \leq \frac{dC}{dt} \leq 1 + \rho
\]

where \(\rho > 0\) is a small number (for example, \(10^{-6}\) seconds per second).

When we have a correct clock, we can measure a time interval \([t, t']\) (where \(t' > t\)) without large errors:
\[
(1 - \rho)(t' - t) \leq H(t') - H(t) \leq (1 + \rho)(t' - t)
\]

This means the hardware clock's measurement of the time interval is close to the real time interval.

\subsection{Software Clock Monotonicity}

Software clocks must be \textbf{monotonic}, which means they never go backward:
\[
t' > t \Rightarrow C(t') > C(t)
\]

If we choose the right parameters for how we calculate the software clock, we can guarantee this property.

\subsection{Clock Resynchronization}

To keep clocks synchronized, we need to update them regularly. The maximum time between updates should be at least:
\[
\frac{D}{2\rho} \text{ seconds}
\]

where \(D\) is the maximum allowed clock difference and \(\rho\) is the clock drift rate bound.

\section{Clock Failures}

Clocks can fail in different ways:

\begin{itemize}
\item \textbf{Crash failure}: The clock simply stops working.
\item \textbf{Arbitrary failure}: The clock behaves in unexpected ways (for example, the Y2K bug where dates jumped from 1999 to 1900 instead of 2000).
\end{itemize}

Important: A clock being \textbf{correct} means it stays within the drift rate bounds. But this is not the same as being \textbf{accurate}. A correct clock still might show the wrong time.

\section{Clock Synchronization Algorithms}

There are several algorithms to synchronize clocks in a distributed system. We can organize them into different types:

\begin{itemize}
\item \textbf{Centralized time services} (request-driven or broadcast-based)
\item \textbf{Distributed time services} (like the Network Time Protocol)
\end{itemize}

\subsection{Christian's Algorithm}

Christian's Algorithm is used for external synchronization. It uses a time server \(S\) that receives the correct time from a UTC source.

\subsubsection{How it Works}

\begin{enumerate}
\item A process \(p\) sends a message \(m_r\) to the time server asking for the current time.
\item The time server receives this message and immediately sends back a message \(m_t\) with the current time \(t\).
\item Process \(p\) receives the reply and measures the round-trip time (RTT) - the time from when it sent the message to when it received the reply.
\item Process \(p\) sets its clock to \(t + \text{RTT}/2\).
\end{enumerate}

The idea behind this is that the server took half the round-trip time to send the reply, so we add RTT/2 to the received time.

\subsubsection{Accuracy}

The accuracy of Christian's algorithm depends on the actual network delays. The accuracy is:
\[
\pm \left(\frac{\text{RTT}}{2} - d_{\text{min}}\right)
\]

where \(d_{\text{min}}\) is the minimum transmission delay we can measure.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{imm/Screenshot 2025-12-04 alle 17.15.39.png}
\end{figure}
The bigger the round-trip time, the less accurate the algorithm. It works best in networks where messages travel quickly and reliably.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{imm/Screenshot 2025-12-04 alle 17.16.49.png}

\end{figure}
if the minimum transmission time is 30, the the accuracy is \(\pm (70/2 - 30) = \pm 5\).
\subsubsection{Advantages and Disadvantages}

\textbf{Advantages}:
\begin{itemize}
\item Simple to understand and implement
\item Works probabilistically even in asynchronous systems
\end{itemize}

\textbf{Disadvantages}:
\begin{itemize}
\item The time server is a single point of failure (if it crashes, synchronization is impossible)
\item The server might be attacked or give wrong information
\end{itemize}

To solve the problem of a single server, we can use multiple synchronized time servers and ask several servers at the same time.

\section{Berkeley's Algorithm}

Berkeley's Algorithm is used for internal synchronization. It uses a master-slave structure where one process (the master) coordinates synchronization with all other processes (the slaves).

\subsection{How it Works}

The algorithm has two steps:

\textbf{Step 1: Measuring clock differences}

\begin{enumerate}
\item The master \(p_m\) sends a message to all processes (including itself) with its current time \(t_1\).
\item When a process \(p_i\) receives this message, it records the time \(t_1\) from the master and sends back a reply with its own current time \(t_2\).
\item When the master receives the reply, it reads its clock again to get time \(t_3\).
\item The master calculates the difference: \(\Delta_i = \frac{t_1 + t_3}{2} - t_2\)
\end{enumerate}

This difference \(\Delta_i\) tells us how much process \(p_i\)'s clock is ahead or behind the master's clock.

\textbf{Step 2: Synchronization}

\begin{enumerate}
\item The master calculates the average of all the differences, ignoring any processes with clocks that are very different (these might be faulty): \(\text{avg} = \text{average}(\Delta_i)\)
\item For each process (including itself), the master calculates a correction: \(\text{Adj}_i = \text{avg} - \Delta_i\)
\item The master sends this correction to each process.
\item Each slave applies the correction to its clock by adding the correction value.
\item If the correction is negative (the clock needs to go backward), the process does not jump backward. Instead, it slows down its clock by hiding system interrupts so that the clock value gradually catches up.
\end{enumerate}

Slowing down the clock instead of jumping backward is important because jumping the clock backward could violate the ordering of events - if event A happened before event B, but then we jump the clock backward, it might look like B happened before A!

\subsubsection{Example}

Imagine we have a master and three slave processes. Initially, their clocks show:
\begin{itemize}
\item Master: 3:05
\item Slave 1: 2:55 (10 minutes slow)
\item Slave 2: 3:00 (5 minutes slow)
\item Slave 3: 3:25 (20 minutes fast)
\end{itemize}

First, we calculate the differences from the master:
\begin{align*}
\Delta_m &= 3:05 - 3:05 = 0 \\
\Delta_1 &= 3:05 - 2:55 = +10 \text{ minutes} \\
\Delta_2 &= 3:05 - 3:00 = +5 \text{ minutes} \\
\Delta_3 &= 3:05 - 3:25 = -20 \text{ minutes}
\end{align*}

Then we calculate the average difference (ignoring slave 3 because 20 minutes seems too much):
\[
\text{avg} = \frac{0 + 10 + 5}{3} = 5 \text{ minutes}
\]

Now we calculate the correction for each process:
\begin{align*}
\text{Adj}_m &= 5 - 0 = +5 \text{ minutes} \\
\text{Adj}_1 &= 5 - 10 = -5 \text{ minutes} \\
\text{Adj}_2 &= 5 - 5 = 0 \text{ minutes} \\
\text{Adj}_3 &= 5 - (-20) = +25 \text{ minutes}
\end{align*}

After applying these corrections:
\begin{itemize}
\item Master: 3:05 + 5 = 3:10
\item Slave 1: 2:55 - 5 = 2:50 (slowed down instead)
\item Slave 2: 3:00 + 0 = 3:00 (no change)
\item Slave 3: 3:25 + 25 = 3:50
\end{itemize}

\subsubsection{Fault Tolerance}

Berkeley's Algorithm can handle some problems:

\begin{itemize}
\item \textbf{Server crash}: If the master crashes, the system elects a new master (this takes some time).
\item \textbf{Faulty slave clocks}: The master ignores any slave clocks that differ too much from the others.
\item \textbf{Wrong values}: The master compares multiple clock values and filters out values that are very different from the others.
\end{itemize}

\section{Network Time Protocol (NTP)}

The Network Time Protocol is the standard method for synchronizing clocks on the Internet. It provides external synchronization with UTC on a worldwide scale.

\subsection{Structure}

NTP uses a hierarchy of time servers:

\begin{enumerate}
\item \textbf{Primary servers}: Connected directly to UTC sources (atomic clocks). These are at the top of the hierarchy.
\item \textbf{Secondary servers}: Synchronized to primary servers. They are in the middle of the hierarchy.
\item \textbf{Client computers}: Get synchronized to secondary servers. These are at the bottom.
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-04 alle 17.25.42.png}
\end{figure}
\subsection{Features}

\begin{itemize}
\item \textbf{Redundancy}: There are many servers, so if one fails, others can take over.
\item \textbf{Scalability}: It works across the entire Internet, not just in one local network.
\item \textbf{Reconfigurable}: If a primary server loses its UTC connection, it becomes a secondary. If a secondary loses its primary, it can find another primary.
\item \textbf{Security}: NTP includes authentication mechanisms to make sure time sources are trustworthy.
\end{itemize}

\subsection{Synchronization Modes}

NTP supports three different modes:

\begin{enumerate}
\item \textbf{Multicast mode}: The server periodically sends its time to all computers in the local network. Clients assume a fixed network delay. This is fast but not very accurate.
\item \textbf{Procedure call mode}: Works like Christian's Algorithm. A client sends a request and the server sends back a timestamp. This is more accurate but requires more network communication.
\item \textbf{Symmetric mode}: Used between pairs of time servers to synchronize with each other. This is only used at high levels of the NTP hierarchy.
\end{enumerate}

\section{Clock Synchronization in Asynchronous Systems}

An important theoretical question: Can we always synchronize clocks perfectly?

The answer is: \textbf{No, not in an asynchronous system}.

In an asynchronous distributed system, we cannot know the upper and lower bounds on message delays. Messages might be very fast or very slow. Because of this, we can only synchronize clocks with some probability - we cannot guarantee perfect accuracy.

We can only achieve a certain level of accuracy when we know the bounds on communication delays. If we do not know these bounds, perfect synchronization is impossible.

\chapter{Logical Clock (5)}
Logical clocks help us order events in a distributed system without relying on physical time. They provide a way to capture the causal relationships between events.
\section{The Happened-Before Relation}

\subsection{Basic Observations}

Let us think about how events happen in a distributed system:

\begin{itemize}
\item When a process (a computer or program) performs actions, these actions happen in the order that the process sees them.
\item When process $p_i$ sends a message to process $p_j$, the sending of the message must happen before the receiving of that message.
\end{itemize}

Based on these ideas, \textbf{Lamport} introduced the \textit{happened-before relation}. This relation captures the idea of \textbf{cause and effect} between events.

\subsection{Definition}

Two events $e$ and $e'$ are connected by the \textbf{happened-before relation} (written as $e \rightarrow e'$) if one of the following conditions is true:

\begin{enumerate}
\item Both events happen in the same process $p_i$, and $e$ happens before $e'$ according to the process's local order.
\item Event $e$ is the sending of a message $m$, and event $e'$ is the receiving of that same message $m$.
\item The relation is \textbf{transitive}: if $e \rightarrow e''$ and $e'' \rightarrow e'$, then $e \rightarrow e'$.
\end{enumerate}

\subsection{Properties}

The happened-before relation creates a \textbf{partial order} over all events in the system. This means that:

\begin{itemize}
\item Some events are ordered: we know that $e \rightarrow e'$ or $e' \rightarrow e$.
\item Some events are not ordered: there may be pairs of events $(e_i, e_j)$ where neither $e_i \rightarrow e_j$ nor $e_j \rightarrow e_i$. We say these events are \textbf{concurrent}, written as $e_i \parallel e_j$.
\end{itemize}

For any two events $e_i$ and $e_j$ in a distributed system, exactly one of the following must be true:

\begin{itemize}
\item $e_i \rightarrow e_j$ (event $i$ happened before event $j$)
\item $e_j \rightarrow e_i$ (event $j$ happened before event $i$)
\item $e_i \parallel e_j$ (events $i$ and $j$ are concurrent)
\end{itemize}

\section{Logical Clocks}

\subsection{Basic Idea}

A \textbf{logical clock} is a simple software counter. It is not a real clock that measures real time. Instead, it is a number that increases to help us order events.

Each process $p_i$ has its own logical clock, which we write as $L_i$. We use this clock to assign a \textbf{timestamp} to each event. If an event $e$ happens in process $p_i$, we give it a timestamp $ts_e = L_i(e)$.

\subsection{Important Property}

The main property of logical clocks is:

\[
\text{If } e \rightarrow e' \text{ then } ts_e < ts_{e'}
\]

This means that if event $e$ happens before event $e'$ in the happened-before relation, then the timestamp of $e$ must be smaller than the timestamp of $e'$.

\subsection{Limitation}

However, logical clocks have a problem. The property works only in one direction. We cannot say:

\[
\text{If } ts_e < ts_{e'} \text{ then } e \rightarrow e'
\]

In other words, just because one event has a smaller timestamp does not always mean it happened before the other event. The events might be concurrent.

\section{Scalar Logical Clock}

\subsection{How It Works}

Scalar logical clock is the simplest type of logical clock. Here is how each process implements it:

\begin{enumerate}
\item \textbf{Initialization}: Each process $p_i$ starts with $L_i = 0$.
\item \textbf{When an event is created}: If $p_i$ performs an action (either sending or receiving a message), it increases its clock by 1: $L_i := L_i + 1$.
\item \textbf{When sending a message $m$}: 
   \begin{itemize}
   \item The process increases its clock: $L_i := L_i + 1$.
   \item The message is given a timestamp $ts = L_i$.
   \item The message and its timestamp are sent to other processes.
   \end{itemize}
\item \textbf{When receiving a message $m$ with timestamp $ts$}:
   \begin{itemize}
   \item The process updates its clock: $L_i := \max(ts, L_i)$.
   \item Then it increases the clock by 1: $L_i := L_i + 1$.
   \end{itemize}
\end{enumerate}

The idea is that a process never goes backward in time. If it receives a message from the future (larger timestamp), it jumps to that time and then continues forward.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-04 alle 17.40.03.png}
\end{figure}
\subsection{Limitations}

Scalar logical clocks have an important limitation. They cannot tell us whether two events are concurrent or ordered:

\begin{itemize}
\item If event $e_1$ has timestamp 1 and event $e_2$ has timestamp 1, we cannot be sure whether they happened in order or if they are concurrent.
\item Even if timestamps are different, the events might still be concurrent (not related by happened-before).
\end{itemize}

This limitation is serious because in many applications, we need to know exactly whether two events are ordered or concurrent.

\section{Vector Logical Clock}

A \textbf{vector clock} for $N$ processes is an array of $N$ integers. Each process $p_i$ maintains its own vector clock, which we write as $V_i$. This vector has $N$ positions, one for each process in the system.

When a process assigns a timestamp to an event, it uses the entire vector, not just a single number.

\subsection{How It Works}

Here is how vector clocks work:

\begin{enumerate}
\item \textbf{Initialization}: Each process $p_i$ starts with $V_i[j] = 0$ for all $j = 1, 2, \ldots, N$.
\item \textbf{When an event is created}: Process $p_i$ increases only its own position: $V_i[i] := V_i[i] + 1$.
\item \textbf{When sending a message $m$}:
   \begin{itemize}
   \item The process increases its clock: $V_i[i] := V_i[i] + 1$.
   \item The entire vector $V_i$ is attached to the message as a timestamp.
   \end{itemize}
\item \textbf{When receiving a message $m$ with timestamp vector $ts$}:
   \begin{itemize}
   \item For each position $j$, the process updates: $V_i[j] := \max(ts[j], V_i[j])$ for all $j = 1, 2, \ldots, N$.
   \item Then it increases its own position: $V_i[i] := V_i[i] + 1$.
   \end{itemize}
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-04 alle 17.44.28.png}
\end{figure}

\subsection{Properties of Vector Clocks}

Vector clocks have special properties that make them very useful:

\begin{itemize}
\item $V_i[i]$ tells us how many events process $p_i$ has created.
\item $V_i[j]$ (where $i \neq j$) tells us how many events from process $p_j$ have affected process $p_i$.
\end{itemize}

To compare two vectors $V$ and $V'$:

\begin{itemize}
\item $V = V'$ if and only if $V[j] = V'[j]$ for all $j = 1, 2, \ldots, N$.
\item $V \leq V'$ if and only if $V[j] \leq V'[j]$ for all $j = 1, 2, \ldots, N$.
\item $V < V'$ (meaning the event with timestamp $V$ happened before the event with timestamp $V'$) if and only if $V \leq V'$ and $V \neq V'$ (and there is at least one position where $V$ is strictly smaller).
\end{itemize}
\subsection{The Power of Vector Clocks}

The most important advantage of vector clocks is that they can tell us exactly which events are ordered and which are concurrent:

\[
\text{Events } e \text{ and } e' \text{ are related by happened-before if and only if } V(e) < V(e')
\]

If $V(e)$ and $V(e')$ are not comparable (one is not smaller than or equal to the other), then the events are concurrent.

\subsection{Practical Example}

Imagine three processes with the following vector timestamps:

\begin{itemize}
\item Event $A$ on $p_1$: $V(A) = [1, 0, 0]$
\item Event $B$ on $p_2$: $V(B) = [1, 1, 0]$
\end{itemize}

Comparing: $[1, 0, 0] < [1, 1, 0]$ because $V(A)[1] \leq V(B)[1]$, $V(A)[2] \leq V(B)[2]$, $V(A)[3] \leq V(B)[3]$, and they are not equal. So event $A$ happened before event $B$.

Now consider:

\begin{itemize}
\item Event $C$: $V(C) = [1, 0, 0]$
\item Event $D$: $V(D) = [0, 0, 1]$
\end{itemize}

Comparing: $[1, 0, 0]$ is not comparable with $[0, 0, 1]$ because position 1 has $1 > 0$ (so $C > D$ in position 1) but position 3 has $0 < 1$ (so $C < D$ in position 3). This means events $C$ and $D$ are concurrent.

\section{Distributed Mutual Exclusion}

\subsection{The Problem}

In many systems, we have multiple processes that want to use the same resource. For example, they might want to write to the same file or use the same database. We cannot allow two processes to use the resource at the same time because they might interfere with each other.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{imm/Screenshot 2025-12-04 alle 21.33.30.png}
    
\end{figure}
The \textbf{mutual exclusion problem} is to design a system where:

\begin{enumerate}
\item \textbf{Mutual Exclusion}: At any time, at most one process is using the resource.
\item \textbf{No Deadlock}: There is always some process that can eventually use the resource.
\item \textbf{No Starvation}: Every process that asks to use the resource will eventually get it.
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-04 alle 21.34.57.png}
\end{figure}
\section{Lamport's Algorithm}

Lamport developed an algorithm that uses scalar logical clocks to solve the mutual exclusion problem.

\subsubsection{Main Idea}

When a process wants to use the resource, it:
\begin{enumerate}
\item Sends a request message to all other processes with a timestamp.
\item Waits for acknowledgments from all other processes.
\item Uses the resource when its request has the smallest timestamp among all pending requests.
\item Sends a release message when it is done, so other processes can use the resource.
\end{enumerate}

\subsubsection{Algorithm Details}

Each process $p_i$ maintains:

\begin{itemize}
\item A counter $ck$ (for "clock"): this is the scalar logical clock.
\item A queue $Q$: this stores pending requests to use the resource.
\end{itemize}

When $p_i$ wants to use the resource:

\begin{enumerate}
\item It increases its counter: $ck := ck + 1$.
\item It sends a REQUEST message with timestamp $ck$ to all other processes.
\item It adds its own request to its queue $Q$.
\end{enumerate}

When $p_i$ receives a REQUEST from $p_j$ with timestamp $t$:

\begin{enumerate}
\item It adds the request (with timestamp $t$ and sender $j$) to its queue.
\item It sends back an acknowledgment.
\end{enumerate}

When $p_i$ receives an acknowledgment from any process with timestamp $t' > t$ (where $t$ is the timestamp of $p_i$'s own request):

\begin{enumerate}
\item It increments the counter and checks if it can use the resource.
\end{enumerate}

$p_i$ can enter and use the resource (the critical section) if:

\begin{enumerate}
\item Its request is in the queue $Q$.
\item Its request has the smallest timestamp in the queue.
\item It has received an acknowledgment from every other process, and all acknowledgments have timestamps larger than its request.
\end{enumerate}

When $p_i$ is done using the resource:

\begin{enumerate}
\item It sends a RELEASE message to all other processes.
\item It removes its request from the queue.
\end{enumerate}

When $p_i$ receives a RELEASE message from $p_j$:

\begin{enumerate}
\item It removes $p_j$'s request from its queue.
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-04 alle 21.44.58.png}
\end{figure}
first, p3 requests the resorce, but during the waiting time, also p1 do another request. Thus the queque is popolated with both requests. When p3 receives all the ack (5- from p2), it can enter the critical section because its request has the smallest timestamp. After p3 releases the resource, p1 can enter.
\subsubsection{Why It Works}

The algorithm guarantees mutual exclusion because of the timestamps. If two processes both want the resource, they will have different timestamps (with a tiebreaker using their process ID). The process with the smaller timestamp gets to use the resource first. All other processes know about the order because they maintain the same queue, so they all agree on who should go first.

\subsubsection{Performance}

Lamport's algorithm requires sending many messages:

\begin{itemize}
\item To use the resource, a process must send $(N-1)$ request messages.
\item It must receive $(N-1)$ acknowledgments.
\item When done, it sends $(N-1)$ release messages.
\item Total: $3(N-1)$ messages for each resource use.
\end{itemize}

If only one process asks for the resource, the delay (time from request to using the resource) is 2 message delays.

\section{Ricart-Agrawala's Algorithm}

Another algorithm, developed by \textbf{Ricart} and \textbf{Agrawala}, improves on Lamport's approach. Instead of waiting for explicit release messages, processes can start granting access as soon as they no longer need the resource.

\subsubsection{Main Improvements}

\begin{itemize}
\item Uses a smaller timestamp comparison to decide priority.
\item Reduces the number of messages needed.
\item Processes can immediately reply to requests (instead of queuing them).
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 12.16.40.png}
\end{figure}
\subsubsection{Local Variables}

Each process $p_i$ maintains:

\begin{itemize}
\item \texttt{replies}: a counter of how many processes have replied.
\item \texttt{State}: can be NCS (not in critical section), Requesting (asking for access), or CS (in critical section).
\item \texttt{Q}: a queue of pending requests.
\item \texttt{Last\_Req}: the timestamp of the most recent request.
\item \texttt{Num}: a counter.
\end{itemize}

\subsubsection{Algorithm Flow}

When $p_i$ wants the resource:

\begin{enumerate}
\item Sets \texttt{State} to "Requesting".
\item Increases \texttt{Num}: \texttt{Num} := \texttt{Num} + 1.
\item Sets \texttt{Last\_Req} := \texttt{Num}.
\item Sends REQUEST(\texttt{Num}) to all other processes.
\item Waits until it has received replies from all $(N-1)$ other processes.
\item Sets \texttt{State} to "CS" and uses the resource.
\end{enumerate}

When $p_i$ receives REQUEST$(t)$ from $p_j$:

\begin{enumerate}
\item If $p_i$ is in CS or if $p_i$ is Requesting and its own timestamp is smaller:
   \begin{itemize}
   \item Add $p_j$'s request to queue $Q$.
   \end{itemize}
\item Otherwise:
   \begin{itemize}
   \item Send REPLY to $p_j$ immediately.
   \end{itemize}
\item Update: \texttt{Num} := $\max(t, \texttt{Num})$.
\end{enumerate}

When $p_i$ finishes using the resource:

\begin{enumerate}
\item For each request in the queue $Q$, send REPLY.
\item Clear the queue and set \texttt{State} to "NCS".
\item Reset reply counter.
\end{enumerate}

When $p_i$ receives REPLY from $p_j$:

\begin{enumerate}
\item Increment the reply counter.
\end{enumerate}
\subsection*{Example Execution}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 12.23.37.png}
\end{figure}
P1 and p2 both request the resource. Both increase their own clock num and send the request.
when p1 receives p2's request, it sees that its own timestamp (1) is smaller than p2's (2), so it queues p2's request and does not reply yet.
when p2 receives p1's request, it sees that its own timestamp (2) is larger than p1's (1), so it immediately replies to p1 and the same do P3.
thus p1 receives all the replies and can enter the critical section.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 12.23.31.png}
\end{figure}
P2 have the reply from P3, and when P1 go out of the critical section, it sends the reply to P2, which can now enter the critical section.

\chapter{Distributed Mutual Exclusion (6)}
\section*{Approaches to Distributed Mutual Exclusion}

There are four main approaches to solve the mutual exclusion problem:

\begin{enumerate}
    \item \textbf{Coordinator-based}: One special process acts as a server and controls access
    \item \textbf{Token-based}: A unique token is passed between processes; only the process with the token can use the resource
    \item \textbf{Quorum-based}: A process asks for permission from a subset of other processes
    \item \textbf{Logical Clock-based}: Processes use logical clocks to order requests fairly
\end{enumerate}

\section{Coordinator-based Algorithm}

\subsection{Basic Idea}

In this approach, one special process acts as a \textbf{coordinator}. This process receives all requests from other processes and decides which process can enter the critical section.

\begin{itemize}
    \item One process is elected as the coordinator
    \item Other processes send requests to the coordinator
    \item The coordinator grants access one at a time
    \item When a process finishes, it notifies the coordinator
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 12.39.56.png}
    
\end{figure}

\subsection{Example Execution}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 12.44.22.png}
\end{figure}

\begin{enumerate}

    \item \textit{p$_3$ requests} the resource by sending REQ to \textit{p$_2$}, like\textit{p$_1$}, but the p3's request arrive before, so p2 set current in cs= p3 . 
   \item The pending list becomes \{p$_1$\}.
    \item The coordinator \textit{p$_2$} grants access to \(p_3\). It sends GRANT\_CS to \(p_3\).
    \item \textit{p$_3$} enters the critical section (state = CS).
    \item \textit{p$_3$} finishes and sends REL to the coordinator.
    \item The coordinator \textit{p$_2$} receives the REL message. Now \textit{current\_in\_CS} = null.
    \item The coordinator grants access to \(p_1\) (next in queue). It sends GRANT\_CS to \(p_1\).
    \item \textit{p$_1$} enters the critical section.
\end{enumerate}

\subsection{Performance Analysis}

\begin{itemize}
    \item \textbf{Entering the critical section}: Requires 2 messages (REQ and GRANT). This takes one Round-Trip Time (RTT).
    
    \item \textbf{Releasing the resource}: Requires only 1 message (REL).
    
    \item \textbf{Load}: The coordinator is a potential bottleneck. All requests go through it, so it receives a lot of messages.
    
    \item \textbf{Advantages}: Simple to understand and implement. The algorithm is efficient in terms of message count.
    
    \item \textbf{Disadvantages}: The coordinator is a single point of failure. If the coordinator crashes, the system stops working. It can also become a performance bottleneck when many processes need access.
\end{itemize}

\section{Token-based Algorithm on Logical Ring}

\subsection{Basic Idea}

In this approach, a unique \textbf{token} circulates among processes. A process can enter the critical section only when it holds the token.

\begin{itemize}
    \item Processes form a logical ring topology
    \item A single token is created and circulates in the ring
    \item Only the process that has the token can use the resource
    \item After using the resource (or if not interested), the token is passed to the next process in the ring
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{imm/Screenshot 2025-12-16 alle 12.54.47.png}
\end{figure}
\subsection{Token Initialization}

During the initialization phase, one process (selected by a deterministic function, e.g., the process with the smallest ID) creates the token and sends it to the next process in the ring. This guarantees that exactly one token exists in the system.

\subsection{Algorithm Details}

\begin{lstlisting}[language=Python, basicstyle=\small, breaklines=true]
// initialization
state = idle
next = p(i+1) mod N
//only p_0 creates the token
if self == p_0:
    send TOKEN to next

upon event request():
    state = waiting

upon event receive pp2pDeliver( TOKEN):
    if state == waiting:
        state = CS
        trigger ok()
    else:
        // Process do not need the resource, pass it on send TOKEN to next
        trigger pp2pSend(Token)to next

upon event release():
    state = idle
    trigger pp2pSend(Token)to next
\end{lstlisting}

\subsection{Performance Analysis}

\begin{itemize}
    \item \textbf{Message overhead}: The algorithm continuously uses communication resources. Even if no process wants the resource, the token keeps circulating around the ring.
    
    \item \textbf{Access delay}: The delay between requesting the resource and getting it varies widely. In the best case (0 time units), a process just receives the token. In the worst case (\textit{N} messages), a process just forwarded the token to the next process and must wait for it to come back.
    
    \item \textbf{Fairness}: The algorithm is fair. Processes take turns in order around the ring.
    
    \item \textbf{Advantages}: Fair ordering of requests. No single point of failure (unlike the coordinator approach).
    
    \item \textbf{Disadvantages}: Wasteful message traffic. Unpredictable access delay. If a process holding the token crashes, the token is lost.
\end{itemize}

\section{Quorum-based Algorithm: Maekawa's Voting}

\subsection{Basic Idea}

Instead of asking all processes for permission, each process only asks permission from a \textbf{subset} of other processes called a \textbf{voting set}. This subset is chosen carefully so that:

\begin{itemize}
    \item Any two voting sets overlap (have at least one process in common)
    \item This overlap guarantees that conflicts are detected
    \item A process needs permission from all members in its voting set to enter the critical section
\end{itemize}
\subsection{Voting Set Requirements}

For each process \(p_i\), we define a voting set \(V_i\) that must satisfy:

\begin{enumerate}
    \item \(p_i \in V_i\): Process \(p_i\) must be in its own voting set (it votes for itself)
    
    \item \(\forall i, j: V_i \cap V_j \neq \emptyset\): Every pair of voting sets must have at least one process in common. This is the key property that ensures mutual exclusion.
    
    \item \(|V_i| = K\): All voting sets have the same size (for fairness)
    
    \item Each process \(p_j\) is contained in exactly \(M\) voting sets (same responsibility principle: each process votes the same number of times)
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 13.04.01.png}
\end{figure}

\subsection{How It Works}

\begin{enumerate}
    \item A process that wants the resource sends a request (REQ) to all processes in its voting set.
    
    \item When a process receives a request:
    \begin{itemize}
        \item If it is already using the resource or has already granted permission to another process, it adds the requester to a pending list
        \item Otherwise, it grants permission (sends ACK) and remembers that it voted
    \end{itemize}
    
    \item A process can enter the resource only after receiving ACK from all processes in its voting set.
    
    \item When a process releases the resource:
    \begin{itemize}
        \item It sends a release message (REL) to all processes in its voting set
        \item If there are processes waiting in the pending list, it grants permission to the next one
    \end{itemize}
\end{enumerate}
\subsection{Computing Optimal Sizes}

Maekawa showed that the optimal values that minimize the voting set size while maintaining correctness are:

\begin{itemize}
    \item \(K \approx \sqrt{N}\)
    \item \(M = K\)
    \item \(|V_i| \approx 2\sqrt{N}\)
\end{itemize}

This is much better than asking all \textit{N} processes (which would require \(N\) messages instead of \(\sqrt{N}\)).

\subsection{Constructing Voting Sets}

A practical way to construct voting sets is:

\begin{enumerate}
    \item Arrange \textit{N} processes in a square matrix of size \(\sqrt{N} \times \sqrt{N}\)
    \item For each process \(p_i\), the voting set \(V_i\) is the union of:
    \begin{itemize}
        \item All processes in the same row as \(p_i\)
        \item All processes in the same column as \(p_i\)
    \end{itemize}
\end{enumerate}

\subsection{Example: 4 Processes}

Let us arrange 4 processes in a \(2 \times 2\) matrix:

\begin{center}
\begin{tabular}{|c|c|}
\hline
\(p_1\) & \(p_2\) \\
\hline
\(p_3\) & \(p_4\) \\
\hline
\end{tabular}
\end{center}

The voting sets are:

\begin{itemize}
    \item \(V_1 = \{p_1, p_2, p_3\}\): Same row as \(p_1\) is \(\{p_1, p_2\}\), same column is \(\{p_1, p_3\}\)
    \item \(V_2 = \{p_1, p_2, p_4\}\): Same row is \(\{p_1, p_2\}\), same column is \(\{p_2, p_4\}\)
    \item \(V_3 = \{p_1, p_3, p_4\}\): Same row is \(\{p_3, p_4\}\), same column is \(\{p_1, p_3\}\)
    \item \(V_4 = \{p_2, p_3, p_4\}\): Same row is \(\{p_3, p_4\}\), same column is \(\{p_2, p_4\}\)
\end{itemize}

Notice that every pair of voting sets intersects. For example, \(V_1 \cap V_2 = \{p_1, p_2\}\), and \(V_1 \cap V_4 = \{p_2, p_3\}\).

\subsection{Example: 9 Processes}

Arrange 9 processes in a \(3 \times 3\) matrix:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\(p_1\) & \(p_2\) & \(p_3\) \\
\hline
\(p_4\) & \(p_5\) & \(p_6\) \\
\hline
\(p_7\) & \(p_8\) & \(p_9\) \\
\hline
\end{tabular}
\end{center}

Each voting set has size \(|V_i| = 5\) (we need 3 processes from the row plus 3 from the column, minus the process itself to avoid counting it twice: \(3 + 3 - 1 = 5\)).


\subsection{Why It Works}

The algorithm guarantees mutual exclusion because of the voting set property. If two processes \(p_i\) and \(p_j\) both want the resource, their voting sets \(V_i\) and \(V_j\) must overlap. At least one process belongs to both voting sets. This common process will grant permission to the first requester and reject the second, preventing both from being in the critical section at the same time.

\subsection{Important Limitation}

\textbf{Maekawa's algorithm is NOT deadlock-free!} There is a potential deadlock scenario:

\begin{itemize}
    \item Process \(p_1\) gets permission from some processes and waits for others
    \item Process \(p_2\) gets permission from some processes and waits for others
    \item There is a circular dependency: both processes are waiting for each other's votes
\end{itemize}

To fix this, additional deadlock prevention mechanisms are needed (like timeouts or deadlock detection).
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 13.15.06.png}
\end{figure}

\chapter{Failure Detection (7)}
Failure Detectors (FD) are mechanisms used in distributed systems to provide information about the status of processes, specifically whether they are operational (correct) or have failed (crashed). They help to overcome the challenges posed by asynchrony and failures in distributed systems.
\section{Timing assumptions}
Failure Detectors can be classified based on the timing assumptions they make about the system:
\begin{itemize}
    \item \textbf{Synchronous FD:} Assume known upper bounds on message transmission times and processing times. They can provide accurate information about process failures.
    \item \textbf{Asynchronous FD:} Do not assume any timing bounds. They may provide inaccurate information, leading to false suspicions of process failures.
    \item \textbf{Partially Synchronous FD:} Assume that the system is asynchronous but eventually becomes synchronous. They can provide more reliable information over time.
\end{itemize}
manipulating the timing assumptions allows to design failure detectors that can provide different levels of accuracy and reliability in detecting process failures.
the time managment can be :
\begin{itemize}
    \item \textbf{Explicit:} Using timeouts to detect failures. If a process does not respond within a specified timeout period, it is suspected to have failed.
    \item \textbf{Implicit:} Relying on the absence of expected messages to infer failures. If a process does not send expected messages, it is suspected to have failed.
\end{itemize}
\section{Failure Detector Abstraction}
A Failure Detector (FD) is an abstraction that provides processes with information about the status of other processes in the system. It can be modeled as a module that generates two types of events:
\begin{itemize}
    \item \textbf{Suspect Event:} Indicates that a process is suspected to have failed.
    \item \textbf{Restore Event:} Indicates that a previously suspected process is now considered operational again.
\end{itemize}
it generally is defined by two properties:
\begin{itemize}
    \item \textbf{Completeness:} Ensures that all crashed processes are eventually suspected by all correct processes.
    \item \textbf{Accuracy:} Ensures that no correct process is ever suspected.
\end{itemize}
Based on these properties, failure detectors can be classified into different types:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-30 alle 17.55.08.png}
    \caption{Failure Detector types based on Completeness and Accuracy}
\end{figure}
\textbf{Observations:}
\begin{itemize}
    \item Strong completeness means that eventually every crashed process is permanently suspected by every correct process.
    \item Weak completeness means that eventually every crashed process is permanently suspected by at least one correct process.
    \item Strong accuracy means that no correct process is ever suspected.
    \item Weak accuracy means that there is at least one correct process that is never suspected.
    \item Eventual strong accuracy means that after some time, no correct process is suspected.
    \item Eventual weak accuracy means that after some time, there is at least one correct process that is never suspected.
\end{itemize}
weakness guarantees that there is at least one correct process that is never suspected, while strong guarantees that no correct process is ever suspected.
Partially speacking, this could be difficult to achieve and thus it is worth to consider weaker forms of accuracy.In particular, eventual accuracy properties are often more practical in real-world distributed systems, where temporary network issues or delays can lead to false suspicions of process failures.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-30 alle 18.05.41.png}
    \caption{Failure Detector properties}
\end{figure}
\section{Perfect Failure Detector (P)}
\subsection*{System model}
We consider a distributed system with the following assumptions.
\begin{itemize}
    \item \textbf{Synchronous System}
    \item \textbf{Crash Failures:} Processes can fail by \emph{crash}: a crashed process stops executing its algorithm forever, but they can't behave maliciously.(bizantine failures are not considered here)
\end{itemize}
using its own clock and the bounds of synchronous model, a process can infer if another process is crashed or just slow.
\subsection*{specification of Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-30 alle 18.25.47.png}
    \caption{Perfect Failure Detector properties}
\end{figure}
\subsection*{implementation of Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-30 alle 18.29.07.png}
    \caption{Perfect Failure Detector implementation}
\end{figure}

\subsubsection*{Initialization}
When the system starts (upon event $\langle p, \text{Init} \rangle$):
\begin{itemize}
    \item $\textit{alive} := \Pi$ --- Initialize the set of all processes
    \item $\textit{detected} := \emptyset$ --- Initialize the set of detected crashed processes as empty
    \item Set a periodic timer to trigger every $\Delta + \Phi$ time units
\end{itemize}
\subsubsection*{Main Event Handlers}
\begin{itemize}
    \item \textbf{Timer Event:} When the timer triggers (upon event $\langle p, \text{timeout} \rangle$):
    \begin{verbatim}
    for each process p in Pi do
      if p not in alive and p not in detected then
        detected := detected union {p};
        trigger <fd, Suspect | p>;
      send heartbeat message to p;
    alive := empty set;
    \end{verbatim}
    The process checks for processes that did not respond with a heartbeat and suspects them if they are not already suspected. It then sends heartbeat messages to all processes and resets the alive set.
    
    \item \textbf{Heartbeat Message Event:} When a heartbeat message is received from process $q$ (upon event $\langle p, \text{Heartbeat} | q \rangle$):
    \begin{verbatim}
    alive := alive union {q};

    \end{verbatim}
    The process that replied, they adds $q$ to the alive set. 
\end{itemize}
es:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4A77-8056-27-0.jpeg}
    \caption{Example of Perfect Failure Detector execution}
\end{figure}
\subsubsection*{correctness}
\begin{itemize}
    \item \textbf{Strong Completeness:} Eventually, every crashed process is permanently suspected by every correct process. This is ensured because crashed processes will not send heartbeat messages, leading to their suspicion.
    \item \textbf{Strong Accuracy:} No correct process is ever suspected. This is ensured because correct processes will always respond with heartbeat messages within the expected time frame.
\end{itemize}
if the timeout is very short, correct processes may be suspected due to network delays or processing time variations.
\newline
if the timeout is very long, crashed processes may not be suspected promptly, leading to delays in failure detection.
\newline
Thus, the choice of timeout value is crucial for the effectiveness of the Perfect Failure Detector.
\section{Eventually Perfect Failure Detector ($\Diamond P$)}
\subsection*{System model}
We consider a distributed system with the following assumptions.
\begin{itemize}
    \item \textbf{Partially Synchronous System:} The system is asynchronous but eventually becomes synchronous.
    \item \textbf{Crash Failures:} Processes can fail by \emph{crash}: a crashed process stops executing its algorithm forever, but they can't behave maliciously. (Byzantine failures are not considered here)
    \item \textbf{Perfect point to point links}
\end{itemize}
Crashed processes can be detected only after an unknown time $t$; before time $t$ there could be false suspicions (it behaves like an asynchronous system).

\subsection*{Basic Construction Rules}
An Eventually Perfect Failure Detector uses timeouts to suspect processes that did not send expected messages:
\begin{itemize}
    \item \textbf{Suspicion mechanism:} A suspect may be wrong. A process $p_i$ may suspect another one $p_j$ if the current timeout is too short.
    \item \textbf{Ready to change judgment:} $\Diamond P$ is ready to change its judgment as soon as it receives a message from $p_j$. In this case, the timeout value is updated to accommodate for longer delays.
    \item \textbf{Permanent suspicion:} If $p_j$ has actually crashed, $p_i$ does not change its judgment anymore.
\end{itemize}

The key difference from Perfect FD is that Eventually Perfect FD can make mistakes initially (false suspicions), but eventually stabilizes and behaves correctly once the system becomes synchronous and timeouts are adjusted appropriately.

\subsection*{specification of Eventually Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-30 alle 20.14.26.png}
    \caption{Eventually Perfect Failure Detector properties}
\end{figure}
\subsection*{implementation of Eventually Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-30 alle 20.20.51.png}
    \caption{Eventually Perfect Failure Detector implementation}
\end{figure}
\subsubsection*{Main Event Handlers}
\begin{itemize}
    \item \textbf{Timer Event:} When the timer triggers (upon event $\langle p, \text{timeout} \rangle$):
    \begin{verbatim}
    If there exists a process q in alive and q in suspected then
        delay= delay + d;
    for each process p in Pi do
      if p not in alive and p not in suspected then
        suspected := suspected union {p};
        trigger <fd, Suspect | p>;
        send heartbeat message to p;
      if p in alive and p in suspected then
        suspected := suspected \ {p};
        trigger <fd, Restore | p>;
        send heartbeat message to p;
    alive := empty set;
    start timer with delay;
    \end{verbatim}
    The process checks for processes that did not respond with a heartbeat and suspects them if they are not already suspected. If a previously suspected process responds, it is restored. The timeout delay is adjusted based on the suspicion status.
    \subsection*{example}
    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4C4B-B34A-EA-0.jpeg}
        \caption{Example of Eventually Perfect Failure Detector execution}
    \end{figure}
\end{itemize}
\section{correctness}
\begin{itemize}
    \item \textbf{Strong Completeness:} If a process crashes, it will eventually be suspected by all correct processes. This is ensured because crashed processes will not send heartbeat messages, leading to their suspicion.
    \item \textbf{Eventual Strong Accuracy:} After some unknown time, no correct process is suspected. This is ensured because once the system becomes synchronous and timeouts are adjusted, correct processes will always respond with heartbeat messages within the expected time frame.
\end{itemize}

\chapter{Leadership Election (7-b)}
Leadership Election is a fundamental problem in distributed systems where processes need to agree on a single process to act as the leader or coordinator for certain tasks. The leader is responsible for making decisions, coordinating actions, and managing resources among the processes.
in the asynchronous system with crash failures,the system stabilizes after some unknown time t, and after t there is a correct process that is never suspected.
thus there are two opstions:
\begin{itemize}
    \item put the assumption on the system (Including links and processes)
    \item create a separate abstraction that encapsulates the assumption 
\end{itemize}
incapsulating the assumption in a separate abstraction is better because it allows to separate concerns, making the system more modular and easier to understand. While do all in a unique algorithm can lead to complex and hard to proof.
thus, we can use a single correct process that monitoring features of the system to elect a leader.
we can use several oracle(called leader election module) that provide information about the processes.
\section {Leader Election}
\subsection*{specification of Leader Election}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.33.44.png}
    \caption{Leader Election properties}
\end{figure}
\subsection*{implementation of Leader Election using Eventually Perfect Failure Detector}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.36.01.png}
    \caption{Leader Election implementation using Eventually Perfect Failure Detector}
\end{figure}
\subsubsection*{Main Event Handlers}
\begin{itemize}
    \item \textbf{Initialization Event:} When the system starts (upon event $\langle p, \text{Init} \rangle$):
    \begin{verbatim}
        leader != maxrank(Pi / suspected) - the process tha have the highest rank among those not suspected;
        leader := max(Pi/ suspected);
        trigger <le, NewLeader | leader>;
    \end{verbatim}
    The process selects the process with the highest rank among those not suspected as the leader and triggers a NewLeader event.
\end{itemize}
\subsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.44.40.png}
    \caption{Example of Leader Election execution}
\end{figure}
the correctness is guaranteed only if there is perfect failure detector. otherwise, there are two possibilities:
\begin{itemize}
    \item best scenario: suspect wrongly a crashed process, but the processes that continue to work are correct.
    \item worst scenario: FALSE POSITIVE, 2 processes could belive to have 2 different leaders.
\end{itemize}
\section{Eventual Leader Election}
\subsection*{specification of Eventual Leader Election}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.49.56.png}
    \caption{Eventual Leader Election properties}
\end{figure}

\subsubsection*{Key Properties and Behavior}
At first, every process may believe in a different leader, but after some unknown time $t$, all correct processes agree on the same correct leader.

\textbf{How it works:}
\begin{itemize}
    \item Every process decides a leader based on the information provided by the Eventually Perfect Failure Detector ($\Diamond P$).
    \item After time $t$ (when the system stabilizes), all correct processes agree on the same correct leader.
    \item We don't know when this time $t$ is, and during this initial period, crashed processes can be elected as leaders (false positives).
    \item Once the system stabilizes and elects a leader, the leader is not changed until it crashes. This stable leader is called \textbf{STABILIZED}.
\end{itemize}

\textbf{Important assumption:} There always exists at least one correct process.
\subsection*{implementation of Eventual Leader Election using Eventually Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.08.24.png}
    \caption{Eventual Leader Election implementation using Eventually Perfect Failure Detector}     
\end{figure}
Example:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.11.03.png}
    \caption{Example of Eventual Leader Election execution}
\end{figure}
\section{ eventual leader election with Crash-Recovery}
chrash-recovery model: processes can crash and later recover, resuming their operations from the state they had before crashing.
in this system the correct processes are p that never crash or that crash, recover and never crash again.
\subsection*{implementation of Eventual Leader Election in Crash-Recovery model}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.16.03.png}
    \caption{Eventual Leader Election implementation in Crash-Recovery model}
\end{figure}   
\subsubsection*{Initialization}
When the system starts (upon event $\langle p, \text{Init} \rangle$):
\begin{verbatim}
    epoch := 0; -- Initialize epoch counter(how many times the process has crashed and recovered)
    store(epoch); -- Store the epoch counter in stable storage
    candidates := empty set; -- Initialize the set of candidate leaders as empty
    trigger < \Omega , Recovery | >; -- Trigger a Recovery event
\end{verbatim}
\subsubsection*{trigger Recovery}
When a process recovers (upon event $\langle p, \text{Recovery} \rangle$):
\begin{verbatim}
    leader := maxrank(Pi) -- Select the process with the highest rank as the leader
    trigger <le, trust | leader>; -- Trigger a trust event with the selected leader
    delay := deltha; -- Initialize the delay for heartbeat messages
    retrieve(epoch); -- Retrieve the epoch counter from stable storage
    epoch := epoch + 1; -- Increment the epoch counter
    store(epoch); -- Store the updated epoch counter in stable storage
    forall q in Pi do
        send [HEARTBEAT, epoch] to q; -- Send heartbeat messages to all processes with the current epoch
    candidates := empty set; -- Reset the set of candidate leaders
    start timer with delay; -- Start the timer with the specified delay
\end{verbatim}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.22.32.png}
    \caption{Eventual Leader Election implementation in Crash-Recovery model}
\end{figure}  
\subsubsection*{ Timeout Event}
When the timer triggers (upon event $\langle p, \text{timeout} \rangle$):   
\begin{verbatim}
    elect new leader from candidates; 
    if the new leader != leader then. -- If a new leader is elected
        leader := new leader;
        trigger <le, trust | leader>;
    for all q in Pi do
        send [HEARTBEAT, epoch] to q; -- Send heartbeat messages to all processes with the current epoch
    candidates := empty set; -- Reset the set of candidate leaders
    start timer with delay; -- Start the timer with the specified delay
\end{verbatim}
\subsubsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.34.26.png}
    \caption{Example of Eventual Leader Election execution in Crash-Recovery model}
\end{figure}
the timer is incremented when a process receive a heartbeat from a process with higher epoch.(p1)
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.37.03.png}
    \caption{Example of Eventual Leader Election execution in Crash-Recovery model - part 2}    
\end{figure}
after the restore of p1, the epoch is incremented and p2 become the leader.

\chapter{ Broadcast Communication(9-10)}
Up to now, the comunication model used is between two processes (like clien-server enviroment).
In distributed systems, it is often necessary to communicate with multiple processes simultaneously. Broadcast communication is a method that allows a process to send a message to all other processes in the system.
\section{Best Effort Broadcast (BEB)}
Best Effort Broadcast (BEB) is a communication primitive that allows a process to send a message to all other processes in a distributed system with the following properties:
\begin{itemize}
    \item \textbf{Validity:} If a correct process broadcasts a message, then all correct processes eventually deliver that message.
    \item \textbf{No Duplication:} No message is delivered more than once to any process.
    \item \textbf{No Creation:} No message is delivered unless it was previously broadcast by some process.
\end{itemize}
\subsection*{specification of Best Effort Broadcast}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.45.59.png}
    \caption{Best Effort Broadcast properties}
\end{figure}
\subsection*{implementation of Best Effort Broadcast}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.47.13.png}
    \caption{Best Effort Broadcast implementation}
\end{figure}
\subsubsection*{correctness}
\begin{itemize}
    \item \textbf{Validity:} If a correct process broadcasts a message, it sends the message to all processes. In our model there are perfect point-to-point links, so all correct processes will eventually receive and deliver the message.
    \item \textbf{No Duplication:} Each process maintains a set of delivered messages. A message is only delivered if it has not been delivered before, ensuring no duplication.
    \item \textbf{No Creation:} perfect point-to-point links ensure that messages are only delivered if they were sent by some process. Since processes only deliver messages they receive, no message can be created out of thin air.
\end{itemize}
\section{ (Regular) Reliable Broadcast(RB)}
Reliable Broadcast (RB) is a communication primitive that extends Best Effort Broadcast by providing stronger guarantees in the presence of process failures. It ensures that messages are delivered reliably even if some processes crash.
the specification of RB are the same of BEB plus:
\begin{itemize}
    \item \textbf{Agreement:} If a correct process delivers a message, then all correct processes eventually deliver that message.
\end{itemize}
difference:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.21.12.png}
    \caption{Difference between Best Effort Broadcast and Reliable Broadcast}
\end{figure}
\section*{implementation of Reliable Broadcast IN Synchronous System }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.22.56.png}
    \caption{Reliable Broadcast implementation in Synchronous System}
\end{figure}
\subsubsection*{initialization}
When the system starts (upon event $\langle p, \text{Init} \rangle$):
\begin{verbatim}
    correct := Pi; -- Initialize the set of correct processes (all processes)
    from [p] := empty set[n]; -- Array to track messages received from each process
\end{verbatim}
\subsubsection*{deliver event}
When a message is delivered (upon event $\langle beb, \text{Deliver} | q, [DATA, s, m]\rangle$):
\begin{verbatim}
    if m not in from[q] then -- If the message has not been received from process q before
        from[q] := from[q] union {m}; -- Add the message to the set of messages received from process q
        trigger <rb, Deliver | s, m>; -- Trigger the delivery event for the reliable broadcast
        if s is not in correct then -- If the sender process s is not in the set of correct processes
            trigger <beb, Broadcast | [DATA, s, m]>; -- Trigger the delivery event for the reliable broadcast
\end{verbatim}
\subsubsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.34.59.png}
    \caption{Example of Reliable Broadcast execution in Asynchronous System}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.36.33.png}
    \caption{Example of Reliable Broadcast execution in Asynchronous System}
\end{figure}
\subsubsection*{Lazy Reliable Broadcast}
in the best scenario, the RB implementation can generate 1 BEB message per RB message .
\newline
in the worst scenario, the RB implementation can generate N-1 BEB messages per RB message.
\newline
if the failure detector is not perfect, the algorithm is not correct, because it may trigger unnecessary retransmissions or fail to detect crashed processes accurately.
\section{Reliable Broadcast (RB) in Asinchronous System}
\subsection*{implementation of Reliable Broadcast IN Asynchronous System }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.43.15.png}
    \caption{Reliable Broadcast implementation in Asynchronous System}
\end{figure}
in this case the best scenario is equal to worst scenario = N BEB messages per RB message, because every message is retransmitted by every process.
\section{ Uniform Reliable Broadcast (URB)}
Uniform Reliable Broadcast (URB) is a communication primitive that extends Reliable Broadcast by providing even stronger guarantees, particularly in the presence of process failures. It ensures that messages are delivered uniformly across all processes, meaning that if any process delivers a message, then all correct processes will eventually deliver that message.
thus, the specification of URB are the same of RB plus:
\begin{itemize}
    \item \textbf{Uniform Agreement:} If any process (correct or faulty) delivers a message, then all correct processes eventually deliver that message.
\end{itemize}
difference:
\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{imm/Screenshot 2025-12-01 alle 17.49.36.png}
    \caption{Difference between Reliable Broadcast and Uniform Reliable Broadcast}
\end{figure}
\subsection*{implementation of Uniform Reliable Broadcast IN Synchronous System }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.50.30.png}
    \caption{Uniform Reliable Broadcast implementation in Synchronous System}
\end{figure}
\begin{verbatim}
    pending := empty set; -- Initialize the set of pending messages as empty
\end{verbatim}
when the message have to be broadcasted by URB, it is added to the pending set.

\begin{verbatim}
upon event <beb, Deliver | q, [DATA, s, m]> do
    ack[m] := ack[m] union {q}; -- Add the process q to the set of acknowledgments for message m
    if m not pending then -- If the message m is not in the pending set
        pending := pending union {m}; -- Add the message m to the pending set
        trigger <beb, broadcast | s, m>; 
\end{verbatim}

\subsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.14.23.png}
    \caption{Example of Uniform Reliable Broadcast execution in Synchronous System}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.27.02.png}
    \caption{Example of Uniform Reliable Broadcast execution in Synchronous System - part 2}
\end{figure}    
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.27.19.png}
    \caption{Example of Uniform Reliable Broadcast execution in Synchronous System - part 3}
\end{figure}
\section{Implementation of Uniform Reliable Broadcast in Asynchronous Systems}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.31.39.png}
    \caption{Uniform Reliable Broadcast implementation in Asynchronous System}
\end{figure}
MANCA
\section{Probabilistic Broadcast (PB)}
Probabilistic Broadcast (PB) is a communication primitive that allows a process to send a message to all other processes in a distributed system with probabilistic guarantees. Unlike traditional broadcast methods that provide deterministic guarantees, PB relies on probabilistic techniques to ensure that messages are delivered to a large fraction of processes with high probability.
the ack mechanism used in RB is not scalable because it requires maintaining an acknowledgment set for each message, which can become large in systems with many processes. 
The probabilistic approach reduces the overhead associated with acknowledgments by allowing processes to make decisions based on probabilistic criteria rather than waiting for explicit acknowledgments from all processes.
\subsection*{specification of Probabilistic Broadcast}
the specification of PB includes the following properties:
\begin{itemize}
    \item \textbf{Probabilistic Validity:} If a correct process broadcasts a message, then with high probability, a large fraction of correct processes eventually deliver that message.
    \item \textbf{No Duplication:} No message is delivered more than once to any process.
    \item \textbf{No Creation:} No message is delivered unless it was previously broadcast by some process.
\end{itemize}
\subsubsection*{gossip Dissemination}
Gossip dissemination is a technique used in probabilistic broadcast to spread messages throughout a distributed system. In this approach, each process randomly selects a subset of other processes to which it forwards the message, creating a "gossip" effect that helps disseminate the message efficiently.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 14.38.18.png}
    \caption{Gossip Dissemination in Probabilistic Broadcast}
\end{figure}
\section*{implementation of Eager Probabilistic Broadcast}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 14.38.58.png}
    \caption{Eager Probabilistic Broadcast implementation}
\end{figure}

\chapter{Consensus (11)}
\section{Consensus Problem}
The consensus problem in distributed systems involves a set of processes that must agree on a single value.
\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-25 alle 20.22.09.png}
    \caption{Consensus Problem}
\end{figure}
\section{consensus specification}
The consensus problem is defined by the following properties:
\begin{itemize}
    \item \textbf{Termination:} Every correct process eventually decides on a value.
    \item \textbf{Agreement:} No two correct processes decide on different values.
    \item \textbf{Validity:} If all correct processes propose the same value $v$, then any correct process that decides must decide $v$.
    \item \textbf{Integrity:} No correct process decides more than once.
\end{itemize}
\subsection*{Impossibility of Consensus in Asynchronous Systems with Failures}
In an asynchronous distributed system where processes can fail by crashing, it is impossible to design a deterministic consensus algorithm that satisfies all the properties of termination, agreement, validity, and integrity.
\newline
This result is known as the FLP impossibility theorem, named after Fischer, Lynch, and Paterson.The key intuition behind the FLP impossibility result is that in an asynchronous system, there is no upper bound on message delivery times or process execution speeds.
\section{Consensus Implementation in Synchronous Systems}
\subsection*{Flooding-based Consensus Algorithm}
In a synchronous system, we can implement a consensus algorithm using a flooding-based approach.All processes exchange their proposed values in rounds, and after a fixed number of rounds, they decide on a value based on the received proposals.
the rounds are fundamental because they provide a structured way for processes to communicate and ensure that all correct processes have the opportunity to share their proposed values before making a decision.(in this way we are sure that there aren't lost values)
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 20.43.55.png}
    \caption{Flooding-based Consensus Algorithm}
\end{figure}

\section{Algorithm Description}

\subsection{Initialization}
When the system starts (upon event $\langle c, \text{Init} \rangle$):
\begin{itemize}
    \item $\textit{correct} := \Pi$ --- Initialize the set of correct processes (all processes)
    \item $\textit{round} := 1$ --- Start from round 1
    \item $\textit{decision} := \bot$ --- The decision is still empty ($\bot$ means ``not decided'')
    \item $\textit{receivedFrom}[r] := [\emptyset]^N$ --- Array tracking from which processes we have received messages for each round
    \item $\textit{proposals}[r] := [\emptyset]^N$ --- Array tracking the proposals received for each round
\end{itemize}

\subsection{Main Event Handlers}

\subsubsection{Propose Event}
When a process proposes a value:
\begin{verbatim}
upon event <c, Propose | v> do
  proposals[1] := proposals[1] union {v};
  trigger <beb, Broadcast | [PROPOSAL, 1, proposals[1]]>;
\end{verbatim}
The process adds its initial value to the proposals of round 1 and broadcasts it to all processes.

\subsubsection{Crash Event}
When the Failure Detector detects a crash:
\begin{verbatim}
upon event <P, Crash | p> do
  correct := correct \ {p};
\end{verbatim}
Removes the process from the set of correct processes.

\subsubsection{Deliver Event}
When a PROPOSAL is received:
\begin{verbatim}
upon event <beb, Deliver | p, [PROPOSAL, r, ps]> do
  receivedFrom[r] := receivedFrom[r] union {p};
  proposals[r] := proposals[r] union ps;
\end{verbatim}
Updates the list of processes from which messages have been received and merges the received proposals.

\subsection{Decision Logic}
The crucial logic for deciding:
\begin{verbatim}
upon correct subseteq receivedFrom[round] AND decision = bottom do
  if receivedFrom[round] = receivedFrom[round-1] then
    decision := min(proposals[round]);
    trigger <beb, Broadcast | [DECIDED, decision]>;
    trigger <c, Decide | decision>;
  else
    round := round + 1;
    trigger <beb, Broadcast | [PROPOSAL, round, proposals[round-1]]>;
\end{verbatim}

This is the most important part:
\begin{itemize}
    \item \textbf{Waiting condition:} The process waits until it has received messages from all correct processes ($\textit{correct} \subseteq \textit{receivedFrom}[\textit{round}]$)
    \item \textbf{Stability:} If the set of processes from which messages were received in this round is the same as in the previous round (no new crashes), we can trust the data
    \item \textbf{Decision:} Chooses the minimum value among the received proposals (deterministic function common to all processes, can be replaced with other functions)
    \item \textbf{Decision broadcast:} Communicates the decided value to all other processes
    \item \textbf{Else:} If the set changes (new crash detected), increment the round and continue
\end{itemize}

\subsection{Receiving DECIDED}
\begin{verbatim}
upon event <beb, Deliver | p, [DECIDED, v]> 
  such that p in correct AND decision = bottom do
  decision := v;
  trigger <beb, Broadcast | [DECIDED, decision]>;
  trigger <c, Decide | decision>;
\end{verbatim}
If a correct process communicates the decided value and the receiving process has not yet decided, it decides this value.

\subsection{Practical Example}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 21.04.25.png}
    \caption{Example of Consensus Algorithm Execution}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 21.10.31.png}
    \caption{P3 decide the min value after the decision of p1}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 21.08.58.png}
    \caption{p2 is the only one thet can decide but crash before the broadcast of the value, so P1 and P3 go to the next round and decide an other value}
\end{figure}

\section{Uniform Consensus Specification}
The difference between uniform consensus and (non-uniform) consensus is that uniform consensus requires \textbf{Uniform Agreement}: no two processes (correct or faulty) can decide different values. In standard consensus, only correct processes are required to agree, meaning a faulty process may decide a different value before crashing.
in the algorithm the decision is choseen at the round N, (at the end) and the set of proposals is the same for all processes, so also faulty processes decide the same value of correct processes.
\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-25 alle 22.55.28.png}
    \caption{Uniform Consensus properties}
\end{figure}
\subsubsection*{Example}
\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-25 alle 22.59.09.png}
    \caption{at the round 3 there is a decision, that is 5 becaus when start a new round the receivedFrom set is = 0}
\end{figure}

\chapter{Paxos (12)}

The Paxos family of algorithms was introduced by Leslie Lamport in 1999 to provide a practical solution to the consensus problem. While it cannot overcome the FLP impossibility result completely, Paxos works by making a reasonable assumption: \textbf{partial synchrony}.

The algorithm guarantees the following properties:

\begin{itemize}
\item \textbf{Safety:} Safety is always guaranteed. This means the algorithm will never violate its safety properties, regardless of timing assumptions.
\item \textbf{Liveness:} The algorithm makes progress (reaches a decision) only when the network behaves ``well'' for long enough periods of time.
\end{itemize}

This compromise allows Paxos to work in real-world distributed systems, even though it cannot provide perfect guarantees under all conditions.

\subsection{Core Properties of Paxos}

Paxos satisfies three essential properties:

\begin{enumerate}
\item \textbf{Only Proposed Values Can Be Chosen:} No value that nobody proposed can become the consensus decision.

\item \textbf{Only One Value Is Chosen:} Different processes cannot decide on different values. Once a value is chosen, it remains the consensus value.

\item \textbf{Processes Learn Only About Chosen Values:} A process can only learn that a value has been chosen if that value was actually chosen by the system.
\end{enumerate}

These properties ensure that the consensus protocol is meaningful and consistent across the entire system.


\subsection{Process Behavior}
\begin{itemize}
\item \textbf{Arbitrary Speed:} Processes can operate at any speed. Some processes may be very fast, while others may be very slow.

\item \textbf{Crash Failures:} Processes may fail by stopping (crashing). Importantly, a crashed process may restart and continue operating.

\item \textbf{Persistent Memory:} After a crash and restart, a process must remember information that it stored before the crash. This is critical because if all information is lost when a process crashes, consensus becomes impossible.
\end{itemize}

\subsection{Message Behavior}
\begin{itemize}
\item \textbf{Arbitrary Delays:} Messages can take any amount of time to reach their destination.

\item \textbf{Possible Duplication:} The same message may be delivered multiple times.

\item \textbf{Possible Loss:} Messages may be lost and never delivered.

\item \textbf{No Corruption:} Messages are never corrupted. What is sent is what is received (if it arrives at all).
\end{itemize}

\section{The Three Roles in Paxos}

Paxos uses three different roles for processes. A single process can play one, two, or all three roles at the same time.

\subsection{Proposers}

\textbf{Proposers} are processes that want to get a value chosen in the system. They initiate the protocol by proposing a value. Multiple proposers can propose different values at the same time.

\subsection{Acceptors}

\textbf{Acceptors} are the processes that actually decide what value will be chosen. They receive proposals from proposers and send responses. The acceptors must remember what they have accepted, even if they crash and restart, because this information is crucial for the algorithm to work correctly.

\subsection{Learners}

\textbf{Learners} are processes that find out what value has been chosen. They do not actively participate in choosing the value but passively receive information about which value was chosen. Learners help communicate the final decision to other processes.

\section{The Basic Idea: Choosing a Value}

\subsection{Single Acceptor Approach}

The simplest way to ensure that only one value is chosen is to have only one acceptor:

\begin{enumerate}
\item A proposer sends its proposed value to the acceptor.
\item The acceptor chooses the first value it receives.
\item The acceptor informs everyone about its decision.
\end{enumerate}

This approach works fine as long as the acceptor never fails. However, this is not realistic. If the only acceptor crashes and all processes depend on its decision, then the system cannot make progress.

\subsection{Multiple Acceptors}

To make the system more reliable, we use multiple acceptors. Now the process works like this:

\begin{enumerate}
\item Each proposer sends its proposal to all (or a subset of) acceptors.
\item Each acceptor can receive proposals from different proposers.
\item We need a rule to decide which value becomes the consensus value.
\end{enumerate}

Here is the problem: different acceptors may receive different sets of proposals. For example:
\begin{itemize}
\item Acceptor $a_1$ receives proposals $v_1, v_2, v_3$
\item Acceptor $a_2$ receives proposals $v_1, v_2$
\item Acceptor $a_3$ receives proposals $v_3$
\end{itemize}

How can we ensure that all acceptors do not choose different values? This is the central challenge that Paxos must solve.

\subsection{The Majority Rule}

Paxos solves this by using a \textbf{majority rule}:

\begin{itemize}
\item An acceptor can accept at most one value.
\item A value is chosen only when a majority of acceptors have accepted it.
\end{itemize}

This majority rule is crucial because of a mathematical property: any two sets of majority size must overlap by at least one element. If we have 5 acceptors, we need 3 acceptors to accept a value for it to be chosen. Any other group of 3 acceptors will share at least one acceptor with the first group.

% ====================
\section{The Protocol Rules}

\subsection{The Problem with Simple Rules}

If we simply apply the rule ``each acceptor accepts only the first proposal it receives,'' we get a problem. Imagine that several proposers send proposals at the same time:

\begin{itemize}
\item Acceptor $a_1$ receives $v_1$ first and accepts it.
\item Acceptor $a_2$ receives $v_2$ first and accepts it.
\item Acceptor $a_3$ receives $v_3$ first and accepts it.
\end{itemize}

Now no value has been accepted by a majority! All three values were accepted by different acceptors, but none of them was accepted by enough acceptors. The system is stuck in a deadlock.

To fix this problem, we need a different approach. Instead of each acceptor accepting only one value, we allow acceptors to accept multiple proposals. However, we add a rule to ensure that all accepted proposals have the same value.

\subsection{Proposal Numbers}

Paxos uses \textbf{proposal numbers} to organize proposals. Each proposal has a unique number, which creates a total ordering of all proposals. 

The key insight is this: all accepted proposals must have the same value.

\begin{quote}
\textbf{Consistency Rule P2:} If a proposal with value \(v\) is chosen, then every higher-numbered proposal that is chosen has value \(v\).
\end{quote}

This rule ensures consistency. Once a value is chosen, all future chosen proposals must have the same value.
Rule P2 talks about chosen proposals, but we need to guarantee something stronger. We need to ensure that no higher-numbered proposal can have a different value from the moment we know that a value might be chosen.

\textbf{P2a} states:

\begin{quote}
If a proposal with value \(v\) is accepted by some acceptor, then every higher-numbered proposal accepted by any acceptor has value \(v\).
\end{quote}

However, P2a is not enough. Imagine that acceptor $a_1$ accepts a proposal with value $v$. Now a new proposer starts and sends a proposal to acceptor $a_2$, which never saw the original proposal with value $v$. Without additional safeguards, $a_2$ might accept a different value.

That is why we need \textbf{P2b}:

\begin{quote}
If a proposal with value \(v\) is chosen, then every higher-numbered proposal issued by any proposer has value \(v\).
\end{quote}

P2b is stronger: it applies to all proposals issued, not just to proposals that have been accepted. This ensures that new proposers do not propose values that contradict what might have been chosen.

\subsection{P2c: The Key Invariant}

To guarantee P2b, we need to maintain an invariant. This invariant, called \textbf{P2c}, is the heart of the Paxos algorithm:

\begin{quote}
For any value \(v\) and number \(n\), if a proposal with value \(v\) and number \(n\) is issued, then there exists a set \(S\) of a majority of acceptors such that one of the following is true:

\begin{enumerate}
\item No acceptor in \(S\) has accepted any proposal numbered less than \(n\), or
\item \(v\) is the value of the highest-numbered proposal among all proposals numbered less than \(n\) that have been accepted by acceptors in \(S\).
\end{enumerate}
\end{quote}

In simpler words: before issuing a proposal with number \(n\), the proposer must learn what value was accepted (if any) by a majority of acceptors in all lower-numbered proposals. If a majority has accepted some value in the past, the proposer must propose that same value. If no majority has accepted anything yet, the proposer can propose any value.

% ====================
\section{The Paxos Algorithm: Two Phases}

\subsection{Overview}

The Paxos algorithm has two main phases:

\begin{enumerate}
\item \textbf{Phase 1:} The proposer learns what value (if any) might have been chosen already. This is called the \textbf{prepare phase}.
\item \textbf{Phase 2:} The proposer sends the value to the acceptors for them to accept. This is called the \textbf{accept phase}.
\end{enumerate}

\subsection{Phase 1: The Prepare Phase}

\subsubsection{Step 1: Proposer Sends Prepare Request}

When a proposer wants to propose a value, it first chooses a new proposal number \(n\) that is higher than any number it has used before. Then, it sends a \textbf{prepare request} to a majority of acceptors:

\begin{center}
\texttt{PREPARE(n)}
\end{center}

The prepare request asks two questions:
\begin{enumerate}
\item Can I make a proposal with number \(n\)?
\item If you have accepted any proposals before, tell me what value the highest-numbered proposal has.
\end{enumerate}

\subsubsection{Step 2: Acceptor Responds to Prepare Request}

When an acceptor receives a prepare request with number \(n\), it must decide:

\begin{itemize}
\item If \(n\) is higher than any prepare request number the acceptor has already responded to, then the acceptor responds positively. It \textbf{promises} not to accept any proposal numbered less than \(n\) in the future. It also tells the proposer about the highest-numbered proposal it has already accepted (if any).

\item If \(n\) is lower than some prepare request the acceptor has already responded to, then the acceptor rejects the prepare request. It tells the proposer the higher number.
\end{itemize}

The response format is:
\begin{itemize}
\item \texttt{ACK(n, n', v')} if the acceptor has accepted a proposal with number \(n'\) and value \(v'\) before.
\item \texttt{ACK(n, $\perp$, $\perp$)} if the acceptor has not accepted anything yet.
\item \texttt{NACK(n')} if \(n\) is too old and the acceptor has already responded to a higher-numbered prepare request with number \(n'\).
\end{itemize}

\subsubsection{Important Point}

The key feature of Phase 1 is that the acceptor makes a \textbf{promise}. By promising not to accept lower-numbered proposals, the acceptor prevents other proposers from getting a majority to accept a different value. This is how Paxos ensures that all higher-numbered proposals will respect what lower-numbered proposals have established.

\subsection{Phase 2: The Accept Phase}

\subsubsection{Step 3: Proposer Sends Accept Request}

Once the proposer has received positive responses from a majority of acceptors, it can send an \textbf{accept request}:

\begin{center}
\texttt{ACCEPT(n, v)}
\end{center}

Here:
\begin{itemize}
\item \(n\) is the proposal number from Phase 1.
\item \(v\) is chosen as follows:
  \begin{itemize}
  \item If any of the responding acceptors have already accepted a proposal, \(v\) is the value of the highest-numbered proposal among those responses.
  \item If none of the responding acceptors have accepted anything, \(v\) is the value the proposer originally wanted to propose.
  \end{itemize}
\end{itemize}

This rule ensures that P2c is maintained. If a majority has already accepted a value, the proposer must propose that same value, not something new.

\subsubsection{Step 4: Acceptor Accepts}

When an acceptor receives an accept request \texttt{ACCEPT(n, v)}, it accepts the proposal if and only if:

\begin{quote}
The acceptor has not already responded to a prepare request with a number higher than \(n\).
\end{quote}

If this condition is met, the acceptor accepts the proposal and remembers that it has accepted the proposal with number \(n\) and value \(v\). This information must be stored persistently (so it survives a crash).

\subsection{Learning the Decision}

\subsubsection{Acceptors Inform Learners}

Whenever an acceptor accepts a proposal, it sends a message to all learners:

\begin{center}
\texttt{ACCEPT(n, v)}
\end{center}

This tells the learners that the acceptor has accepted this proposal.

\subsubsection{Learners Decide}

When a learner receives \texttt{ACCEPT(n, v)} messages from a majority of acceptors (all with the same \(n\) and \(v\)), the learner knows that the value \(v\) has been chosen. The learner can then:

\begin{enumerate}
\item Decide that \(v\) is the consensus value.
\item Send \texttt{DECIDE(v)} to all other learners.
\end{enumerate}

When other learners receive \texttt{DECIDE(v)}, they also decide that \(v\) is the consensus value.

% ====================
\section{A Practical Problem: Liveness}

\subsection{The Issue of Competing Proposers}

While Paxos guarantees safety (the right value will be chosen), there is a liveness problem. Imagine two proposers that are trying to propose at the same time:

\begin{enumerate}
\item Proposer 1 sends \texttt{PREPARE(1)}.
\item Proposer 2 sends \texttt{PREPARE(2)}.
\item Acceptors respond to Proposer 2 with \texttt{NACK(2)} for Proposer 1's request (because 2 is higher than 1).
\item Proposer 1 now sends \texttt{PREPARE(3)}.
\item Acceptors respond to Proposer 1 with \texttt{NACK(3)} for Proposer 2's request (because 3 is higher than 2).
\item This continues forever...
\end{enumerate}

The proposers keep trying to ``outdo'' each other, and the system never reaches a decision. Both proposers can keep proposing higher numbers indefinitely.

\subsection{The Solution: Leader Election}

To solve the liveness problem, Paxos uses a \textbf{leader election mechanism}. The idea is simple:

\begin{itemize}
\item Processes run a separate leader election protocol.
\item Once a leader is elected, only the leader can propose new values.
\item If the leader fails, the system elects a new leader, and the protocol continues.
\end{itemize}

With a leader, the competing proposers problem goes away. Only one proposer (the leader) is trying to propose, so there is no ``proposal number war.''

When a leader is working correctly and the network is partially synchronous, Paxos can make progress and reach a decision quickly. If the leader fails, the system will eventually elect a new leader and continue.

% ====================
\section{Paxos in Practice}

\subsection{Not Just Theory}

Paxos might sound like a theoretical exercise, but it is actually used in real systems:

\begin{itemize}
\item \textbf{Google:} Uses Paxos in Chubby, its lock service that coordinates many machines.
\item \textbf{Yahoo:} Uses Paxos in ZooKeeper, a system for distributed configuration and coordination.
\item Other companies also use Paxos-like algorithms in their infrastructure.
\end{itemize}

\subsection{Why Not Always Use Paxos?}

Despite its importance, Paxos is not used in every distributed system. There are several reasons:

\begin{enumerate}
\item \textbf{Complexity:} Paxos is difficult to understand and implement correctly. The algorithm requires careful handling of message ordering, timeouts, and failure scenarios.

\item \textbf{Reconfiguration:} If you need to change the set of nodes running Paxos (for example, to add more machines), the algorithm becomes even more complex.

\item \textbf{Scalability:} Paxos requires that every acceptor communicate with every proposer. As the system grows larger, this communication overhead can become a bottleneck.

\item \textbf{Other Alternatives:} Researchers have developed other consensus algorithms that may be simpler or more scalable in certain scenarios. For example, Raft is often seen as an easier-to-understand alternative.
\end{enumerate}

\chapter{ Ordered Communication (13)}
In distributed systems, many processes send and receive messages.
\textbf{Ordered communication} defines rules about the order in which
processes deliver these messages.

Typical ordering properties are:
\begin{itemize}
  \item \textbf{FIFO Order}
  \item \textbf{Causal Order}
  \item \textbf{Total Order} (also called \emph{atomic} order)
\end{itemize}

These properties are \textbf{orthogonal} to reliability.
A \emph{reliable} broadcast only says that messages are not lost or
duplicated. It does not say \emph{in which order} the messages are
delivered.

If there is no ordered communication, strange situations can happen.
For example, a client first sends ``reserve a seat'' and then
``cancel my reservation''. If the server delivers the cancel message
before the reserve message, the server cancels a reservation that
never existed.

To avoid such anomalies, we combine:
\begin{itemize}
  \item \textbf{reliable broadcast} + one or more \textbf{ordering} properties.
\end{itemize}

\section*{FIFO Broadcast}
FIFO broadcast guarantees the following idea:

If one process \(p\) sends two messages \(m_1\) and then \(m_2\),
\emph{every} correct process delivers \(m_1\) before \(m_2\).

So, for each sender, the order of deliveries respects the order of sends.

\subsection*{Specification}

The FIFO broadcast abstraction exports two operations:
\begin{itemize}
  \item \textbf{FIFO\_Broadcast(\(m\))}: a process sends a message \(m\) to all.
  \item \textbf{FIFO\_Deliver(\(m\))}: a process delivers a message \(m\).
\end{itemize}

It satisfies:
\begin{itemize}
  \item All properties of reliable broadcast (no loss, no duplication,
        agreement between correct processes).
  \item \textbf{FIFO Order}: for any process \(p\) and any processes
        \(q_1, q_2\), if \(p\) broadcasts \(m_1\) before \(m_2\),
        then every correct receiver delivers \(m_1\) before \(m_2\).
\end{itemize}

There are two variants:
\begin{itemize}
  \item \textbf{Uniform FIFO broadcast}: the FIFO property also holds
        for faulty processes that deliver messages.
  \item \textbf{Non-uniform FIFO broadcast}: the FIFO property is
        required only for correct processes.
\end{itemize}

\subsection*{Implementation}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 14.48.27.png}
    \caption{Implementation of FIFO Broadcast using Reliable Broadcast}
\end{figure}

This mechanism guarantees that, for each sender, messages are delivered
in the order of their sequence numbers, so FIFO order holds.
\subsection*{Example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 15.08.02.png}
    \caption{p2 receives m2 before m1, so it puts m2 in the buffer until m1 is delivered}
\end{figure}
\section{ Causal Order Broadcast}
Causal order broadcast respects \textbf{cause--effect} relationships
between messages.

The causal order is a generalization of the \emph{happened-before}
relation \(\rightarrow\) in distributed systems.

A message \(m_1\) \emph{may have caused} another message \(m_2\)
(written \(m_1 \rightarrow m_2\)) if:
\begin{enumerate}
  \item Some process \(p\) broadcasts \(m_1\) and later broadcasts
        \(m_2\).
  \item Some process \(p\) delivers \(m_1\) and later broadcasts
        \(m_2\).
  \item There is a message \(m'\) such that
        \(m_1 \rightarrow m'\) and \(m' \rightarrow m_2\)
        (transitivity).
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 15.11.09.png}
\end{figure}
A causal broadcast guarantees:
if \(m_1 \rightarrow m_2\), then every correct process delivers
\(m_1\) before \(m_2\).

\subsection{Specification }

The causal broadcast abstraction exports:
\begin{itemize}
  \item \textbf{CO\_Broadcast(\(m\))}: send \(m\) to all.
  \item \textbf{CO\_Deliver(\(m\))}: deliver \(m\).
\end{itemize}

Properties:
\begin{itemize}
  \item All properties of reliable broadcast.
  \item \textbf{Causal Order}: if \(\text{broadcast}(m_1)\)
        causally precedes \(\text{broadcast}(m_2)\), then each
        correct process delivers \(m_1\) before \(m_2\).
\end{itemize}

As before, we can define uniform and non-uniform variants.
Important facts:
\begin{itemize}
  \item Causal broadcast is \textbf{reliable broadcast + causal order}.
  \item \textbf{Causal order implies FIFO order}. If a process sends
        \(m_1\) and then \(m_2\), we have \(m_1 \rightarrow m_2\),
        so any causal implementation must deliver \(m_1\) before \(m_2\).
  \item The opposite is not true:
        \textbf{FIFO order does not imply causal order}.
  \item Causal order can be seen as:
        \[
          \text{Causal Order} = \text{FIFO Order} + \text{Local Order}
        \]
\end{itemize}

\textbf{Local Order} means:
if a process delivers message \(m_a\) and then sends message \(m_b\),
then no correct process can deliver \(m_b\) before it has delivered
\(m_a\).
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 15.17.05.png}
\end{figure}

\subsection{Implementation with Vector Clocks-WAITING}
A common implementation uses \textbf{vector clocks}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 15.23.38.png}
\end{figure}
Each process \(p_i\) keeps:
\begin{itemize}
  \item A vector clock \(V_i[1..n]\), where \(n\) is the number of
        processes.
\end{itemize}

\paragraph{Receiving}
When a process \(p_j\) receives a message \(m\) with vector clock
\(m.VC\), it:
\begin{enumerate}
  \item Puts \(m\) in a waiting set if the causal condition is not yet
        satisfied.
  \item The condition to CO\_Deliver(\(m\)) is:
        \[
          \forall x \in \{1,\dots,n\}:
          \quad m.VC[x] \leq V_j[x]
        \]
        except possibly for the sender component, which is handled
        carefully depending on the exact algorithm.
  \item When the condition is true, it:
    \begin{enumerate}
      \item CO\_Delivers \(m\).
      \item Updates its own vector clock as:
            \[
              V_j[x] := \max(V_j[x], m.VC[x])
            \]
            for all \(x\).
    \end{enumerate}
\end{enumerate}

The idea is that a process delays the delivery of a message until it
has seen (delivered) all messages that causally precede it.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 15.26.25.png}
\end{figure}
\subsection*{ Safety }
\textbf{Safety Property:}
Let two broadcast messages $m$ and $m'$ such that $\text{broadcast}(m) \rightarrow \text{broadcast}(m')$. Then each process must deliver $m$ before $m'$.

\textbf{Key Observation:}
If $m$ is the $k$-th message sent by process $p_i$, then its vector clock at index $i$ is:
\[ m.VC[i] = k - 1 \]
(assuming 0-based indexing for past messages).

\subsubsection*{Proof Strategy}
The proof proceeds by \textbf{induction} on the \textbf{causal distance}.

\textbf{Definition (Causal Distance $k$):}
Two broadcast events $b$ and $b'$ ($b \rightarrow b'$) have distance $k$ if there is a sequence of $k$ intermediate broadcast events $b_1 \dots b_k$ such that:
\[ b \rightarrow b_1 \rightarrow \dots \rightarrow b_k \rightarrow b' \]
and no other message exists "between" any adjacent pair in the chain (direct dependency).

\subsubsection*{Base Case ($k=0$)}
We assume $\text{broadcast}(m) \rightarrow \text{broadcast}(m')$ and there is \textbf{no} intermediate message $m''$. This implies a direct causal link. We distinguish two cases.

\subsubsection*{Case 1: Same Sender (FIFO)}
Both $m$ and $m'$ are sent by the same process $p_i$.
\begin{itemize}
    \item Since $m$ is sent before $m'$, if $m$ is the $h$-th message, then $m'$ is the $(h+1)$-th message.
    \item Timestamps: $m.VC[i] = h-1$ and $m'.VC[i] = h$.
    \item Delivery Condition for receiver $p_j$: To deliver $m'$, we need $m'.VC[i] \le V_j[i]$.
    \item This means we need $h \le V_j[i]$.
    \item But $V_j[i]$ becomes $h$ \textbf{only after} $p_j$ delivers the $h$-th message from $p_i$, which is $m$.
    \item \textbf{Conclusion:} $m'$ can only be delivered after $m$.
\end{itemize}

\subsubsection*{Case 2: Different Senders (Local Order)}
$m$ is sent by $p_i$ and $m'$ is sent by $p_j$.
\begin{itemize}
    \item Since $\text{broadcast}(m) \rightarrow \text{broadcast}(m')$ directly, it means $p_j$ must have \textbf{delivered} $m$ before sending $m'$.
    \item Let $m.VC[i] = h-1$.\item When $p_j$ sends $m'$, it includes its current vector clock. Since $p_j$ already delivered $m$, its vector clock $V_j$ must reflect that: $V_j[i] \ge h$.
    \item Therefore, the timestamp on $m'$ will have $m'.VC[i] \ge h$.
    \item Delivery Condition for a third receiver $p_k$: To deliver $m'$, $p_k$ checks if $m'.VC[i] \le V_k[i]$.
    \item This implies $p_k$ must satisfy $V_k[i] \ge h$.
    \item $V_k[i] \ge h$ is only true if $p_k$ has already delivered the $h$-th message from $p_i$, which is $m$.
    \item \textbf{Conclusion:} $p_k$ must deliver $m$ before it can deliver $m'$.
\end{itemize}
\subsection{Inductive Step ($k > 0$)}
\textbf{Hypothesis:} The property holds for causal distance $< k$.
\textbf{Goal:} Prove it holds for distance $k$.

Consider a chain $b \rightarrow b_1 \rightarrow \dots \rightarrow b_k \rightarrow b'$.
\begin{itemize}
    \item By the chain structure, the distance between $b$ and $b_k$ is less than $k$ (specifically $k-1$ steps to $b_k$, or consider the direct link $b_k \rightarrow b'$).
    \item By inductive hypothesis, $m$ (associated with $b$) is delivered before $m_k$ (associated with $b_k$).
    \item By the base case (distance 0), $m_k$ is delivered before $m'$.
    \item By transitivity of delivery order: $m$ is delivered before $m'$.
\end{itemize}
\subsection{Liveness}
\textbf{Liveness:} Eventually, every message is delivered (assuming reliable channels).

\subsection{Implementation with Vector Clocks- NO-WAITING}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 15.48.43.png}
\end{figure}
the difference with the previous implementation is that there is a store of all messages. When a message arrives, if is in order it is delivered, otherwise all messages necessary for the delivery of the new message are delivered from its history.
\subsection*{ Example }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 15.56.34.png}    
\end{figure}
\section*{4. Total Order (Atomic) Broadcast}
Total order broadcast is stronger than FIFO and causal order.

It guarantees that:
\begin{itemize}
  \item All correct processes deliver the \textbf{same set} of messages.
  \item They deliver them in the \textbf{same sequence}.
\end{itemize}

This abstraction is often called \textbf{atomic broadcast} because
each message appears as one atomic action: either \emph{all} correct
processes deliver it, or none deliver it, and all messages are totally
ordered with respect to each other.

\subsection*{4.3 Relation with FIFO and Causal Order}

Total order is \textbf{orthogonal} to FIFO and causal order.

For example:
\begin{itemize}
  \item It is possible to have total order, but no FIFO order.
        A process \(p\) can send messages \(m_1, m_2, \dots, m_n\),
        and all correct processes deliver them in reverse order
        \(m_n, \dots, m_1\).
        The system still satisfies total order, but not FIFO.
  \item It is also possible to have total order without causal order,
        because the agreed global order may violate some causal
        relationships.
\end{itemize}

Sometimes we combine properties:
\begin{itemize}
  \item \textbf{FIFO atomic broadcast}:
        reliable broadcast + FIFO order + total order.
  \item \textbf{Causal atomic broadcast}:
        reliable broadcast + causal order + total order.
\end{itemize}

\chapter{Total Order Broadcast (14)}

Total Order Broadcast (TOB) is a fundamental communication primitive in distributed systems that ensures all processes deliver messages in the same order.

\section{System model}
We consider a distributed system with the following assumptions.
\begin{itemize}
    \item \textbf{Processes:}
    \begin{itemize}
        \item There is a static set of processes $p_1, \dots, p_n$.
        \item Processes can fail by \emph{crash}: a crashed process stops executing its algorithm forever, but they can't behave maliciously.(bizantine failures are not considered here)
        \item A process that never crashes is called a \emph{correct} process.
        \end{itemize}
    \item \textbf{Communication:}Channels between correct processes are \emph{perfect}: messages are not lost, not duplicated, and no fake messages are created.
    \item \textbf{Asynchronous:} there is no known upper bound on message transmission time or processing time.
\end{itemize}

\section{Total Order specification}
TO (Total Order) is composed by 4 specifications:
\begin{itemize}
    \item \textbf{Validity:} If a correct process broadcasts a message $m$, then it eventually delivers $m$.
    \item \textbf{Uniform Agreement:} If a process delivers a message $m$, then all correct processes eventually deliver $m$.
    \item \textbf{Uniform Integrity:} For any message $m$, every process delivers $m$ at most once, and only if $m$ was previously broadcast by its sender.
    \item \textbf{Uniform Total Order:} If two processes $p_i$ and $p_j$ deliver two messages $m$ and $m'$, then $p_i$ delivers $m$ before $m'$ if and only if $p_j$ delivers $m$ before $m'$.
\end{itemize}
Validity parla di consegna assicurata per messaggi validi.
\newline
Uniform Agreement parla di accordo sull'insieme dei messaggi consegnati.
\newline
Uniform Integrity parla di evitare duplicati e messaggi inventati.
\newline
Uniform Total Order parla di accordo sull'ordine esatto di consegna.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 18.09.55.png}
    \caption{Total Order Broadcast properties}
\end{figure}
A Uniform properties is stronger than a non-uniform one because it applies to all processes, not just correct ones.

\section {Non-Uniform Validity-Uniform Integrity}
Such that our system have perfect channel and chra failures, the properties satisfied are:
\newline
NUV (Non-Uniform Validity): If a correct process broadcasts a message $m$, then it eventually delivers $m$.
\newline
UI (Uniform Integrity): For any message $m$, every process delivers $m$ at most once, and only if $m$ was previously broadcast by its sender.
\newline
the properties that are not satisfied are: Agreement and Total Order.
\subsubsection*{Agreement property}
\begin{itemize}
    \item \textbf{Non-Uniform Agreement:} If a CORRECT process delivers a message $m$, then all correct processes eventually deliver $m$.
    \item \textbf{Uniform Agreement:} If a process delivers a message $m$, then all correct processes eventually deliver $m$.
    \newline
    \newline
    The difference is that in Uniform Agreement, the process delivering $m$ can be faulty.The correct processes deliver the same set of messages, while faulty processes may deliver a different set of messages or none at all.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 18.41.44.png}
        \caption{Non-Uniform Agreement vs Uniform Agreement}
    \end{figure}
    UA: If P3 (faulty process) delivers m2, then P1 and P2 (correct processes) must also deliver m2.
    \newline
    NUA: If P3 (faulty process) delivers m5, it does not imply that P1 and P2 (correct processes) must also deliver m5.
\end{itemize}
\subsubsection*{Total Order property}
\begin{itemize}
    \item \textbf{Strong Uniform Total Order:} if some process deliver message m before m', then a process deliver m' only after m.
    \item \textbf{Weak Uniform Total Order:} If two processes $p_i$ and $p_j$ deliver two messages $m$ and $m'$, then $p_i$ delivers $m$ before $m'$ if and only if $p_j$ delivers $m$ before $m'$.
\end{itemize}
    The difference is that in SUTO, all processes must deliver the same set of messages in the same order, while in WUTO, processes may deliver different sets of messages, but the relative order of any two messages is consistent across processes that deliver both messages.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 18.48.48.png}
        \caption{Strong Uniform Total Order vs Weak Uniform Total Order}
    \end{figure}
    SUTO: if process p3,delivers message m4 before m5, then process p4 must also deliver m4 before m5.
    \newline
    WUTO: Each process may deliver a different set of messages, but the relative order between any two messages is always the same for processes that deliver both messages.

\begin{itemize}
    \item \textbf{Strong non-Uniform Total Order:} if some CORRECT process deliver message m before m', then a CORRECT process deliver m' only after m.
    \item \textbf{Weak non-Uniform Total Order:} If two CORRECT processes $p_i$ and $p_j$ deliver two messages $m$ and $m'$, then $p_i$ delivers $m$ before $m'$ if and only if $p_j$ delivers $m$ before $m'$.
\end{itemize}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 19.02.37.png}
        \caption{}
    \end{figure}
    Strong assumptions is more restrictive than weak assumptions (SUTO=>WUTO- SNUTO=>WNUTO).
\section{Examples of Total Order Broadcast Variants}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.06.png}
    \hfill
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.15.png}
    \caption*{UA + SUTO: All processes deliver the same set of messages in the same order. \newline NUA + SUTO: Only correct processes deliver the same set/order; faulty process may miss messages ($m_4$, $m_5$ missing).}
    \vspace{1em}
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.26.png}
    \hfill
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.40.png}
    \caption*{UA + WUTO: All processes deliver the same set with consistent relative order. \newline NUA + WUTO: Only correct processes deliver the same set with consistent relative order.\newline}
    \vspace{1em}
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.48.png}
    \hfill
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.56.png}
    \caption*{UA + WNUTO: Correct processes deliver the same set with consistent relative order; faulty process behavior is undefined. \newline NUA + WNUTO: Correct processes deliver the same set with consistent relative order; $m_5$ missing from some processes.}
\end{figure}

\chapter{Software Replication (15)}
Software replication is a technique used in distributed systems to enhance reliability, availability, and fault tolerance by maintaining multiple copies (replicas) of software components across different nodes or servers. This approach ensures that if one replica fails or becomes unavailable, other replicas can continue to provide the same services without interruption.
\section{Goals of Software Replication}
The primary goals of software replication include:
\begin{itemize}
    \item \textbf{Fault Tolerance:} By having multiple replicas, the system can continue to operate even if some replicas fail.
    \item \textbf{High Availability:} Replication helps ensure that services remain available to users, even during maintenance or unexpected outages. Replicas improve availability from $1-p$ to $1-p^r$, where $p$ is the probability of failure of a single replica and $r$ is the number of replicas.
    \item \textbf{Performance Improvement:} Replicas can be distributed across different geographical locations, allowing users to access the nearest replica, reducing latency and improving response times.
\end{itemize}
\section{System Model}
the system is composed of a set of processes(clients):
\begin{itemize}
    \item Processes can fail by crash.
    \item There is a static set of servers(replicas): $s_1, s_2, \dots, s_n$.
    \item Channels between correct processes are perfect.
    \item The system is asynchronous.
\end{itemize}
processes interact with a set of object X, located at different sites managed by processes.
the object X export two operations:
\begin{itemize}
    \item \textbf{READ()}: returns the current value of the object X.
    \item \textbf{WRITE(v)}: updates the value of the object X to v.
\end{itemize}
after issuing an invocation, a process waits for the response before issuing another invocation.
An other difference is between:
\begin{itemize}
    \item \textbf{State-less:} a service that haven't update.
    \item \textbf{State-full:} a service that have updateds and have control of the current state (like database).

\end{itemize}
\section{Requirements for Software Replication}
To ensure the effectiveness of software replication, several key requirements must be met:
\begin{itemize}
    \item replicas of an object x are noted as $x_1, x_2, \dots, x_n$.
    \item invocation of replica $x_i$ located in site s is handled by process $p_j$ also located in s.
    \item assume taht $p_j$ crashed exactly when $x_i$ chrashes.
\end{itemize}
\section{Consistency Criteria}
Consistency criteria define the rules and guarantees for how replicas of an object maintain a coherent state across the distributed system. Different consistency models provide varying levels of guarantees regarding the visibility and ordering of updates across replicas. Here are some common consistency criteria used in software replication:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Immagine JPEG-46C5-B8EC-2C-0.jpeg}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4276-A13A-45-0.jpeg}
\end{figure}
\section{Replication Techniques}
\subsection{Primary Backup}
In the primary-backup approach, one replica is designated as the primary, while the others serve as backups. The primary replica handles all client requests and propagates updates to the backup replicas. If the primary fails, one of the backups is promoted to become the new primary.
Handles non-deterministic operations by logging non-deterministic choices at the primary and replaying them at the backups.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-16 alle 17.01.50.png}
    \caption{Primary-Backup Replication}
\end{figure}
How to guarantee linearizability in primary-backup:the order in which the primary processes client requests must be the same order in which the backups process them.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Appunti Generali-76.jpg}
\end{figure}
\section{Active replication}
Treats all replicas as equal peers. Each replica processes client requests independently and concurrently. Clients send requests to all replicas, and each replica executes the request and returns the result to the client. The client then selects the result from one of the replicas.
This approch requires deterministic operations to ensure that all replicas produce the same result for a given request.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4DAC-B4F4-39-0.jpeg}
    \caption{Active Replication}
\end{figure}
\section{Primary Backup vs Active replication}
primary-backup(leader-election):Synchronous replication, simpler to implement, but has a single point of failure (the primary).
\newline
active replication(Paxos):Partial Synchronous replication, more complex to implement, but provides higher fault tolerance and availability.

\chapter{Registers (16-17)}

A \textbf{register} is a shared variable accessed by multiple processes through simple read and write operations. In traditional multiprocessor machines, processes communicate through registers at the hardware level, and these registers form the physical memory. However, in distributed systems with message passing and no physical shared memory, we need to create an abstraction that allows processes to simulate a shared register using network communication.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 11.35.16.png}
\end{figure}

A register is a data structure that stores a value and allows processes to access this value through two main operations:

\begin{itemize}
\item \textbf{Read operation:} \texttt{read()} returns the current value of the register without modifying it.
\item \textbf{Write operation:} \texttt{write(v)} writes value \texttt{v} into the register and returns confirmation when complete.
\end{itemize}

\subsection{Key Assumptions}

When working with registers in distributed systems, we make the following assumptions:

\begin{enumerate}
\item A register stores only positive integers and is initialized to 0.
\item Each value written is uniquely identified.
\item Processes are sequential: a process cannot start a new operation before the previous one finishes.
\end{enumerate}

\subsection{Register Notation}

We use the notation $(X, Y)$ to describe a register where:
\begin{itemize}
\item $X$ = number of processes that can write
\item $Y$ = number of processes that can read
\end{itemize}

For example:
\begin{itemize}
\item $(1,1)$ register: one writer and one reader
\item $(1,N)$ register: one writer and $N$ readers
\end{itemize}

\section{Register Operations}

\subsection{Operation Structure}

Every read or write operation has two key events:

\begin{enumerate}
\item \textbf{Invocation event:} The process calls the operation.
\item \textbf{Return event:} The process receives the result.
\end{enumerate}

An operation is \textbf{complete} if both invocation and return events have occurred. A \textbf{failed operation} is one where the process crashes before receiving the return event.

\subsection{Precedence Between Operations}

Given two operations $o$ and $o'$:
\begin{itemize}
\item $o$ \textbf{precedes} $o'$ if the return event of $o$ happens before the invocation event of $o'$
\item $o$ and $o'$ are \textbf{concurrent} if there is no precedence relation between them
\end{itemize}

An important rule: a complete operation can precede another operation, but an incomplete operation cannot have a defined precedence relation.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-17 alle 11.44.35.png}
\end{figure}
\section{Register Semantics}

\subsection{Serial System with No Failures}

In a simple scenario where processes access the register one after another and never fail:

\begin{itemize}
\item \textbf{Liveness:} Each operation eventually completes.
\item \textbf{Safety:} Each read operation returns the value that was written most recently.
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-17 alle 11.46.07.png}
\end{figure}
\subsection{Concurrent Access Without Failures}

When multiple processes can access the register at the same time, we must decide what value a read should return. This leads to different register semantics: \textbf{regular} and \textbf{atomic} registers.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-17 alle 11.46.44.png}
\end{figure}
\subsection{Failures}

When processes can crash, a write operation might not complete. In this case, a read operation may return:
\begin{itemize}
\item The value written by a completed write operation, or
\item The value being written by an incomplete (failed) write operation
\end{itemize}

\section{Register specification}

\subsection{(1,N) Regular Register Specification}

A $(1,N)$ regular register must satisfy:

\begin{enumerate}
\item \textbf{Termination:} If a correct process calls an operation, it eventually receives a response.
\item \textbf{Validity:} A read returns either the last value written or the value currently being written.
\end{enumerate}

\textbf{Important limitation:} In a regular register, a process can read value $v$ and then later read value $v'$, even if the writer wrote $v'$ first and then $v$, as long as these operations are concurrent.
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-17 alle 11.50.18.png}
\end{figure}
The second read can return 5 because the second write(6) might happen after the read even though it logically comes after write(5).

\section{Atomic Registers}

\subsection{(1,N) Atomic Register Specification}

An atomic register is a regular register with an additional property:

\begin{enumerate}
\item \textbf{Termination:} If a correct process calls an operation, it eventually receives a response.
\item \textbf{Validity:} A read returns either the last value written or the value currently being written.
\item \textbf{Ordering:} If a read returns $v_2$ after another read that precedes it returned $v_1$, then $v_1$ cannot have been written after $v_2$.
\end{enumerate}

The ordering property is the key difference. It prevents the problematic behavior we saw in regular registers.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-17 alle 11.52.43.png}
\end{figure}
\subsection{Why Ordering Matters}

Atomic registers ensure consistency in time order. If process $p_1$ reads value 5 and process $p_2$ reads value 6 later, then process $p_2$ cannot read 5 after that. The writes must have actually happened in that order: 5 before 6.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Appunti Generali-82 2.jpg}
\end{figure}
\section{Implementation: Regular Registers}

\subsection{Read-One-Write-All Algorithm}

This is the simplest algorithm for implementing a $(1,N)$ regular register in a crash-failure model:

\textbf{Idea:}
\begin{itemize}
\item Each process keeps a local copy of the register value.
\item A read operation simply returns the local copy.
\item A write operation updates the value on all processes.
\end{itemize}

\textbf{Requirements:}
\begin{itemize}
\item Perfect failure detector (crashes are reliably detected): Strong accuracy and completeness.
\item Perfect point-to-point communication links: Reliable message delivery (no duplication or creation).
\item Best-effort broadcast : no duplication, no creation, best-effort validity.
\end{itemize}

\textbf{properties:}
\begin{itemize}
\item termination: if a correct process calls an operation, it eventually receives a response.
\item validity: a read returns either the last value written or the value currently being written.
\end{itemize}

\begin{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 12.05.59.png}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 12.06.09.png}
    \end{figure}
\end{figure}
For \texttt{write(v)}:
\begin{enumerate}
\item The writer sends the new value to all processes using broadcast.
\item The writer waits for acknowledgments from all processes that have not crashed.
\item Once the writer gets all acknowledgments, the write completes.
\end{enumerate}

For \texttt{read()}:
\begin{enumerate}
\item The reader simply returns its local copy of the value.
\end{enumerate}

\textbf{Performance:}
\begin{itemize}
\item Write: at most $2N$ messages (broadcast + acknowledgments)
\item Read: 0 messages (local operation)
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Appunti Generali-85.jpg}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4C3A-9393-23-0.jpeg}
\end{figure}

\subsection{Majority Voting Algorithm}

When perfect failure detection is not available, we use the Majority Voting approach:

\textbf{Key ideas:}
\begin{itemize}
\item Each value is assigned a unique timestamp.
\item The writer and readers use a set of witness processes (a quorum).
\item A quorum is a majority of all processes.
\item Any two quorums must have at least one process in common (intersection property).
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 12.19.25.png}
\end{figure}
\textbf{Algorithm steps:}

For \texttt{write(v)}:
\begin{enumerate}
\item Assign a new timestamp to the value.
\item Send the value with its timestamp to a majority of processes.
\item Wait for acknowledgments from a majority.
\item Complete when all acknowledgments arrive.
\end{enumerate}

For \texttt{read()}:
\begin{enumerate}
\item Send a read request to a majority of processes.
\item Collect responses and select the one with the highest timestamp.
\item Return that value.
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Appunti Generali-92.jpg}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Appunti Generali-93.jpg}
\end{figure}


\textbf{Performance:}
\begin{itemize}
\item Write: at most $2N$ messages
\item Read: at most $2N$ messages
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4D8B-96D6-C2-0.jpeg}
\end{figure}
\section{Implementation: Atomic Registers}
\subsection*{properties of atomic registers}
\begin{itemize}
\item termination: if a correct process calls an operation, it eventually receives a response.
\item validity: a read returns either the last value written or the value currently being written.
\item \textbf{ordering}: if a read returns $v_2$ after another read that precedes
\end{itemize}

To implement an atomic register, we use a two-phase approach:

\textbf{Phase 1:} Use a $(1,N)$ regular register to build a $(1,1)$ atomic register.

\textbf{Phase 2:} Use multiple $(1,1)$ atomic registers to build a $(1,N)$ atomic register.

\subsection{Phase 1: Regular to Atomic (1,1)}
\subsubsection*{Implementation}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 13.58.54.png}
\end{figure}

The reader tracks timestamps of previously read values to prevent going backwards:

\textbf{Algorithm:}
\begin{enumerate}
\item Each write operation stores the value together with a timestamp: $(v, ts)$.
\item The reader remembers the timestamp of the last value it read.
\item Each read operation returns the current value and updates the remembered timestamp.
\item If a new read returns a value with a lower timestamp than the previous read, the reader returns the old value instead.
\end{enumerate}

This ensures the ordering property: timestamps can only increase.

\subsection*{ Performance}
the same as regular register because no more messages are exchanged.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 14.06.28.png}
\end{figure}
\subsection{Phase 2: (1,1) Atomic to (1,N) Atomic}

To extend from one reader to multiple readers:

\textbf{Idea:} The writer maintains a separate $(1,1)$ atomic register for each reader.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 14.07.06.png}
\end{figure}
\textbf{Algorithm:}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 14.28.57.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{imm/Screenshot 2025-12-17 alle 14.39.06.png}
    \caption{write operation ends when arrive all ack}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-17 alle 14.40.51.png}
    \caption{p2 starts a read operation, thus analyzes the value in the matrix (column: pw-p2, pr1-pr2, pr2-pr2) and writes the highest value in its row}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 14.47.47.png}
    \caption{although the write operation ends after the first read, pr2 have the correct value because pw-pr2 ends faster than pr1-pr2 or pw-pw, after the first read, pr2 update 5 in its row.Thus when start the second read pr1 using (pr2-pr1) have also the correct value.--ORDERING}
\end{figure}
This preserves the ordering property across all readers because each reader tracks its own timestamp.
\section*{Performance Analysis}
write: N write operations on the (1,1) atomic register
\newline
read: Nread operations on the (1,1) atomic register and N writes to update the reader's timestamp.

\section*{Fail-stop Algorithm}
\subsection*{Read-impose Write-All Algorithm}
This is an optimized implementation for a crash-failure model:

\textbf{Key idea:} ``The read operation writes.''

\textbf{Algorithm:}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 15.04.54.png}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 15.07.59.png}
\end{figure}

\begin{enumerate}
\item The writer increment its timestamp and wait for the ack. whan all correct processes respond, the write opertion ends.
\item When a reader performs a read, it:
  \begin{itemize}
  \item sends write operation with its value and timestamp.
  \item waits for acknowledgments from all processes.
  \item when all acks arrive, set reading=false and the operation ends.
  \end{itemize}
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 15.47.40.png}
\end{figure}
\textbf{Performance:}
\begin{itemize}
\item Write: at most $2N$ messages
\item Read: at most $2N$ messages
\end{itemize}

\section*{Fail silent Algorithm}
For the crash-silent model (no perfect failure detection):

\textbf{Algorithm:}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 16.06.27.png}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 16.06.35.png}
    \caption{when the realist obtain the majority start the write opertion}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-17 alle 16.06.43.png}
    \caption{the write operation is different from the previous one because the writer send have a different timestamp }
\end{figure}

\textbf{Performance:}
\begin{itemize}
\item Write: at most $2N$ messages
\item Read: at most $4N$ messages (query majority + write back to majority)
\end{itemize}

\section{Correctness Properties}

All register implementations must satisfy three core properties:

\subsection{Termination}

If a process does not crash, every operation it starts must eventually complete. This is guaranteed by our communication primitives (reliable links, broadcast) and failure detectors.

\subsection{Validity}

A read operation must return a meaningful value:
\begin{itemize}
\item Either the value from the last completed write
\item Or a value that was being written when the read happened
\end{itemize}

\subsection{Ordering (Atomic Only)}

For atomic registers, if read 1 completes before read 2 starts, and read 1 returns value $v_1$ with timestamp $ts_1$, then read 2 cannot return a value with a lower timestamp.

This is achieved through timestamps and the ``impose'' operation, which forces processes to update their copies.


\chapter{da riverdere}
Paxos
\end{document}