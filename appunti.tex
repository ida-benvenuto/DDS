\documentclass[a4paper,11pt]{report}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}

\title{Dependable Distributed Systems}
\author{Ida Francesca Benvenuto}
\date{november-december 2025}

\begin{document}

\maketitle
\chapter{Time in Distributed System(4)}

\section{Introduction}

In a distributed system, many processes run on different computers that are connected by a network. These processes need to work together to complete computations, and they can only communicate by sending messages to each other. 

Many applications need to order events correctly and synchronize processes to work properly. Examples include air traffic control, network monitoring, and financial systems where we need to track when orders are made and executed. This is why \textbf{time is very important in distributed systems}.

\section{Why is Time Important?}

Time is a quantity that we want to measure and understand. Many algorithms depend on time to work correctly:

\begin{itemize}
\item \textbf{Data consistency}: When we have copies of data stored in multiple places, we need to make sure all copies show the same information at the same time.
\item \textbf{Authentication}: We need to know when messages were sent to prevent security problems.
\item \textbf{Double processing avoidance}: We must not process the same request twice by accident.
\end{itemize}

To solve these problems, we need to be able to put events in the correct order. This means we need to understand and order events that happen in different places at almost the same time.

\section{Why is Using Time Difficult in Distributed Systems?}

The main problem is that we need all processes to agree on what time it is. It is easy to order events that happen in the same process because they happen one after another. However, when events happen in different processes at about the same time, we cannot easily know which event happened first. 

In a distributed system with network delays and processing delays, it is impossible to have one clock that all processes share. Each process has its own local clock, and these clocks will show different times.

\section{System Model}

A distributed system is made up of a set of processes \(P = \{p_1, p_2, \ldots, p_n\}\). Each process runs on a single computer with no shared memory. Each process \(p_i\) has a state \(s_i\) that changes as the process executes.

Processes can only communicate by exchanging messages through the network. They cannot access other processes' memory directly.

\section{Events and Computation}

Each process creates a sequence of events during its execution:

\begin{itemize}
\item \textbf{Internal events}: Events that change the process state (for example, calculating something).
\item \textbf{External events}: Events where the process sends or receives a message.
\end{itemize}

We use the notation \(e_i^k\) to mean the $k$-th event created by process \(p_i\). 
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-04 alle 17.01.16.png}
\end{figure}
\subsection{Ordering Events}

For events that happen in the same process, we can order them easily. We write \(e \rightarrow_i e'\) if event \(e\) happens before event \(e'\) in process \(p_i\).

The \textbf{local history} of a process is the sequence of all events that it creates. For process \(p_1\), the local history might be:
\[
\text{history}(p_1) = h_1 = e_1^1, e_1^2, e_1^3, e_1^4, e_1^5, e_1^6
\]
the \textbf{partial local history} is the sequence of events that a process has created so far, which can be different for each process.

When processes communicate, they send messages to each other. We write \(e \rightarrow e'\) if event \(e\) happens before event \(e'\) in the global history of the system.

The \textbf{global history} is the collection of all local histories from all processes in the system.

\section{Timestamping and Physical Clocks}

One way to solve the ordering problem is to attach a label (called a \textbf{timestamp}) to each event. If we give each event a number that represents when it happened, we can order events from different processes.

A simple idea is to have each process put a timestamp on its events using its local hardware clock. However, this does not always work well because:

\begin{enumerate}
\item Hardware clocks are not perfectly accurate.
\item Different computers' clocks show different times.
\item Clocks drift (they gradually move away from the correct time).
\end{enumerate}

\section{Physical Computer Clocks}

Each computer has a \textbf{hardware clock} made of an oscillator (something that vibrates at a regular speed) and a counter that increases by one for each vibration. The operating system reads this hardware clock and creates a \textbf{software clock}.

The software clock \(C_i(t)\) for process \(p_i\) at real time $t$ is:
\[
C_i(t) = H_i(t) + \text{offset}
\]

where \(H_i(t)\) is the hardware clock value and offset is a correction value.

\subsection{Clock Accuracy}

The software clock \(C_i(t)\) is an approximation of the real time $t$. However, it is not perfect:

\begin{itemize}
\item It can be different from the real time.
\item Different processes may have different values because hardware is not identical.
\end{itemize}

In practice, a 64-bit software clock might show time in nanoseconds (very small units of time).

\subsection{Clock Resolution}

An important question is: How small must the time step be between updates so we can tell two events apart? The resolution must be smaller than the time between two important events.

\section{Problems with Clock Synchronization}

Two important measurements describe how well clocks stay synchronized:

\begin{itemize}
\item \textbf{Skew}: The difference between two clocks at the same time: \(|C_i(t) - C_j(t)|\). This is how much two clocks disagree with each other.
\item \textbf{Drift rate}: How fast a clock moves away from the correct time. It is measured as change per second. For example, a drift rate of 2 microseconds per second means a clock increases by 1 second + 2 microseconds for each real second that passes.
\end{itemize}

Regular quartz clocks (the type in most computers) drift by about 1 second in 11 to 12 days, which is a drift rate of about \(10^{-6}\) seconds per second. Better quality quartz clocks have a drift rate of \(10^{-7}\) to \(10^{-8}\) seconds per second. Only atomic clocks (based on atomic oscillators) can achieve very small drift rates of \(10^{-13}\) seconds per second.

\section{Universal Time Coordinated (UTC)}

\textbf{UTC} (Universal Time Coordinated) is an international standard for measuring time. It is based on International Atomic Time, which is defined by how long it takes a cesium atom to complete a certain number of state transitions.

When we say 1 second, we mean the time for a cesium atom to make 9,192,631,770 state transitions.

UTC is the time standard used worldwide, and it is available from specialized time sources called UTC sources.

\section{Internal and External Synchronization}

We need to understand two types of clock synchronization:

\subsection{External Synchronization}

In external synchronization, all processes synchronize their clocks with an external time source \(S\) (a UTC source).

We say that clocks \(C_i\) are \textbf{externally synchronized} with accuracy \(D > 0\) if, for all processes \(i = 1, 2, \ldots, N\) and for all real times $t$ in some time interval:
\[
|S(t) - C_i(t)| < D
\]

This means each local clock differs from the external time source by less than \(D\).

\subsection{Internal Synchronization}

In internal synchronization, all processes synchronize their clocks with each other, not necessarily with an external source.

We say that clocks are \textbf{internally synchronized} with accuracy \(D > 0\) if, for all pairs of processes \(i, j = 1, 2, \ldots, N\) and for all real times $t$ in some time interval:
\[
|C_i(t) - C_j(t)| < D
\]

This means all local clocks agree with each other within accuracy \(D\).

\subsection{Relationship Between Internal and External Synchronization}

Important note: Clocks that are internally synchronized are not necessarily externally synchronized. Even if all clocks agree with each other, they might all be wrong compared to UTC!

However, if a set of processes is externally synchronized with accuracy \(D\), then it is also internally synchronized with accuracy \(2D\).

\section{Correct Clocks}

A hardware clock \(H\) is called a \textbf{correct clock} if its drift rate stays within a limited bound. We write this as:
\[
1 - \rho \leq \frac{dC}{dt} \leq 1 + \rho
\]

where \(\rho > 0\) is a small number (for example, \(10^{-6}\) seconds per second).

When we have a correct clock, we can measure a time interval \([t, t']\) (where \(t' > t\)) without large errors:
\[
(1 - \rho)(t' - t) \leq H(t') - H(t) \leq (1 + \rho)(t' - t)
\]

This means the hardware clock's measurement of the time interval is close to the real time interval.

\subsection{Software Clock Monotonicity}

Software clocks must be \textbf{monotonic}, which means they never go backward:
\[
t' > t \Rightarrow C(t') > C(t)
\]

If we choose the right parameters for how we calculate the software clock, we can guarantee this property.

\subsection{Clock Resynchronization}

To keep clocks synchronized, we need to update them regularly. The maximum time between updates should be at least:
\[
\frac{D}{2\rho} \text{ seconds}
\]

where \(D\) is the maximum allowed clock difference and \(\rho\) is the clock drift rate bound.

\section{Clock Failures}

Clocks can fail in different ways:

\begin{itemize}
\item \textbf{Crash failure}: The clock simply stops working.
\item \textbf{Arbitrary failure}: The clock behaves in unexpected ways (for example, the Y2K bug where dates jumped from 1999 to 1900 instead of 2000).
\end{itemize}

Important: A clock being \textbf{correct} means it stays within the drift rate bounds. But this is not the same as being \textbf{accurate}. A correct clock still might show the wrong time.

\section{Clock Synchronization Algorithms}

There are several algorithms to synchronize clocks in a distributed system. We can organize them into different types:

\begin{itemize}
\item \textbf{Centralized time services} (request-driven or broadcast-based)
\item \textbf{Distributed time services} (like the Network Time Protocol)
\end{itemize}

\subsection{Christian's Algorithm}

Christian's Algorithm is used for external synchronization. It uses a time server \(S\) that receives the correct time from a UTC source.

\subsubsection{How it Works}

\begin{enumerate}
\item A process \(p\) sends a message \(m_r\) to the time server asking for the current time.
\item The time server receives this message and immediately sends back a message \(m_t\) with the current time \(t\).
\item Process \(p\) receives the reply and measures the round-trip time (RTT) - the time from when it sent the message to when it received the reply.
\item Process \(p\) sets its clock to \(t + \text{RTT}/2\).
\end{enumerate}

The idea behind this is that the server took half the round-trip time to send the reply, so we add RTT/2 to the received time.

\subsubsection{Accuracy}

The accuracy of Christian's algorithm depends on the actual network delays. The accuracy is:
\[
\pm \left(\frac{\text{RTT}}{2} - d_{\text{min}}\right)
\]

where \(d_{\text{min}}\) is the minimum transmission delay we can measure.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{imm/Screenshot 2025-12-04 alle 17.15.39.png}
\end{figure}
The bigger the round-trip time, the less accurate the algorithm. It works best in networks where messages travel quickly and reliably.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{imm/Screenshot 2025-12-04 alle 17.16.49.png}

\end{figure}
if the minimum transmission time is 30, the the accuracy is \(\pm (70/2 - 30) = \pm 5\).
\subsubsection{Advantages and Disadvantages}

\textbf{Advantages}:
\begin{itemize}
\item Simple to understand and implement
\item Works probabilistically even in asynchronous systems
\end{itemize}

\textbf{Disadvantages}:
\begin{itemize}
\item The time server is a single point of failure (if it crashes, synchronization is impossible)
\item The server might be attacked or give wrong information
\end{itemize}

To solve the problem of a single server, we can use multiple synchronized time servers and ask several servers at the same time.

\section{Berkeley's Algorithm}

Berkeley's Algorithm is used for internal synchronization. It uses a master-slave structure where one process (the master) coordinates synchronization with all other processes (the slaves).

\subsection{How it Works}

The algorithm has two steps:

\textbf{Step 1: Measuring clock differences}

\begin{enumerate}
\item The master \(p_m\) sends a message to all processes (including itself) with its current time \(t_1\).
\item When a process \(p_i\) receives this message, it records the time \(t_1\) from the master and sends back a reply with its own current time \(t_2\).
\item When the master receives the reply, it reads its clock again to get time \(t_3\).
\item The master calculates the difference: \(\Delta_i = \frac{t_1 + t_3}{2} - t_2\)
\end{enumerate}

This difference \(\Delta_i\) tells us how much process \(p_i\)'s clock is ahead or behind the master's clock.

\textbf{Step 2: Synchronization}

\begin{enumerate}
\item The master calculates the average of all the differences, ignoring any processes with clocks that are very different (these might be faulty): \(\text{avg} = \text{average}(\Delta_i)\)
\item For each process (including itself), the master calculates a correction: \(\text{Adj}_i = \text{avg} - \Delta_i\)
\item The master sends this correction to each process.
\item Each slave applies the correction to its clock by adding the correction value.
\item If the correction is negative (the clock needs to go backward), the process does not jump backward. Instead, it slows down its clock by hiding system interrupts so that the clock value gradually catches up.
\end{enumerate}

Slowing down the clock instead of jumping backward is important because jumping the clock backward could violate the ordering of events - if event A happened before event B, but then we jump the clock backward, it might look like B happened before A!

\subsubsection{Example}

Imagine we have a master and three slave processes. Initially, their clocks show:
\begin{itemize}
\item Master: 3:05
\item Slave 1: 2:55 (10 minutes slow)
\item Slave 2: 3:00 (5 minutes slow)
\item Slave 3: 3:25 (20 minutes fast)
\end{itemize}

First, we calculate the differences from the master:
\begin{align*}
\Delta_m &= 3:05 - 3:05 = 0 \\
\Delta_1 &= 3:05 - 2:55 = +10 \text{ minutes} \\
\Delta_2 &= 3:05 - 3:00 = +5 \text{ minutes} \\
\Delta_3 &= 3:05 - 3:25 = -20 \text{ minutes}
\end{align*}

Then we calculate the average difference (ignoring slave 3 because 20 minutes seems too much):
\[
\text{avg} = \frac{0 + 10 + 5}{3} = 5 \text{ minutes}
\]

Now we calculate the correction for each process:
\begin{align*}
\text{Adj}_m &= 5 - 0 = +5 \text{ minutes} \\
\text{Adj}_1 &= 5 - 10 = -5 \text{ minutes} \\
\text{Adj}_2 &= 5 - 5 = 0 \text{ minutes} \\
\text{Adj}_3 &= 5 - (-20) = +25 \text{ minutes}
\end{align*}

After applying these corrections:
\begin{itemize}
\item Master: 3:05 + 5 = 3:10
\item Slave 1: 2:55 - 5 = 2:50 (slowed down instead)
\item Slave 2: 3:00 + 0 = 3:00 (no change)
\item Slave 3: 3:25 + 25 = 3:50
\end{itemize}

\subsubsection{Fault Tolerance}

Berkeley's Algorithm can handle some problems:

\begin{itemize}
\item \textbf{Server crash}: If the master crashes, the system elects a new master (this takes some time).
\item \textbf{Faulty slave clocks}: The master ignores any slave clocks that differ too much from the others.
\item \textbf{Wrong values}: The master compares multiple clock values and filters out values that are very different from the others.
\end{itemize}

\section{Network Time Protocol (NTP)}

The Network Time Protocol is the standard method for synchronizing clocks on the Internet. It provides external synchronization with UTC on a worldwide scale.

\subsection{Structure}

NTP uses a hierarchy of time servers:

\begin{enumerate}
\item \textbf{Primary servers}: Connected directly to UTC sources (atomic clocks). These are at the top of the hierarchy.
\item \textbf{Secondary servers}: Synchronized to primary servers. They are in the middle of the hierarchy.
\item \textbf{Client computers}: Get synchronized to secondary servers. These are at the bottom.
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-12-04 alle 17.25.42.png}
\end{figure}
\subsection{Features}

\begin{itemize}
\item \textbf{Redundancy}: There are many servers, so if one fails, others can take over.
\item \textbf{Scalability}: It works across the entire Internet, not just in one local network.
\item \textbf{Reconfigurable}: If a primary server loses its UTC connection, it becomes a secondary. If a secondary loses its primary, it can find another primary.
\item \textbf{Security}: NTP includes authentication mechanisms to make sure time sources are trustworthy.
\end{itemize}

\subsection{Synchronization Modes}

NTP supports three different modes:

\begin{enumerate}
\item \textbf{Multicast mode}: The server periodically sends its time to all computers in the local network. Clients assume a fixed network delay. This is fast but not very accurate.
\item \textbf{Procedure call mode}: Works like Christian's Algorithm. A client sends a request and the server sends back a timestamp. This is more accurate but requires more network communication.
\item \textbf{Symmetric mode}: Used between pairs of time servers to synchronize with each other. This is only used at high levels of the NTP hierarchy.
\end{enumerate}

\section{Clock Synchronization in Asynchronous Systems}

An important theoretical question: Can we always synchronize clocks perfectly?

The answer is: \textbf{No, not in an asynchronous system}.

In an asynchronous distributed system, we cannot know the upper and lower bounds on message delays. Messages might be very fast or very slow. Because of this, we can only synchronize clocks with some probability - we cannot guarantee perfect accuracy.

We can only achieve a certain level of accuracy when we know the bounds on communication delays. If we do not know these bounds, perfect synchronization is impossible.


\chapter{Failure Detection (7)}
Failure Detectors (FD) are mechanisms used in distributed systems to provide information about the status of processes, specifically whether they are operational (correct) or have failed (crashed). They help to overcome the challenges posed by asynchrony and failures in distributed systems.
\section{Timing assumptions}
Failure Detectors can be classified based on the timing assumptions they make about the system:
\begin{itemize}
    \item \textbf{Synchronous FD:} Assume known upper bounds on message transmission times and processing times. They can provide accurate information about process failures.
    \item \textbf{Asynchronous FD:} Do not assume any timing bounds. They may provide inaccurate information, leading to false suspicions of process failures.
    \item \textbf{Partially Synchronous FD:} Assume that the system is asynchronous but eventually becomes synchronous. They can provide more reliable information over time.
\end{itemize}
manipulating the timing assumptions allows to design failure detectors that can provide different levels of accuracy and reliability in detecting process failures.
the time managment can be :
\begin{itemize}
    \item \textbf{Explicit:} Using timeouts to detect failures. If a process does not respond within a specified timeout period, it is suspected to have failed.
    \item \textbf{Implicit:} Relying on the absence of expected messages to infer failures. If a process does not send expected messages, it is suspected to have failed.
\end{itemize}
\section{Failure Detector Abstraction}
A Failure Detector (FD) is an abstraction that provides processes with information about the status of other processes in the system. It can be modeled as a module that generates two types of events:
\begin{itemize}
    \item \textbf{Suspect Event:} Indicates that a process is suspected to have failed.
    \item \textbf{Restore Event:} Indicates that a previously suspected process is now considered operational again.
\end{itemize}
it generally is defined by two properties:
\begin{itemize}
    \item \textbf{Completeness:} Ensures that all crashed processes are eventually suspected by all correct processes.
    \item \textbf{Accuracy:} Ensures that no correct process is ever suspected.
\end{itemize}
Based on these properties, failure detectors can be classified into different types:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-30 alle 17.55.08.png}
    \caption{Failure Detector types based on Completeness and Accuracy}
\end{figure}
\textbf{Observations:}
\begin{itemize}
    \item Strong completeness means that eventually every crashed process is permanently suspected by every correct process.
    \item Weak completeness means that eventually every crashed process is permanently suspected by at least one correct process.
    \item Strong accuracy means that no correct process is ever suspected.
    \item Weak accuracy means that there is at least one correct process that is never suspected.
    \item Eventual strong accuracy means that after some time, no correct process is suspected.
    \item Eventual weak accuracy means that after some time, there is at least one correct process that is never suspected.
\end{itemize}
weakness guarantees that there is at least one correct process that is never suspected, while strong guarantees that no correct process is ever suspected.
Partially speacking, this could be difficult to achieve and thus it is worth to consider weaker forms of accuracy.In particular, eventual accuracy properties are often more practical in real-world distributed systems, where temporary network issues or delays can lead to false suspicions of process failures.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-30 alle 18.05.41.png}
    \caption{Failure Detector properties}
\end{figure}
\section{Perfect Failure Detector (P)}
\subsection*{System model}
We consider a distributed system with the following assumptions.
\begin{itemize}
    \item \textbf{Synchronous System}
    \item \textbf{Crash Failures:} Processes can fail by \emph{crash}: a crashed process stops executing its algorithm forever, but they can't behave maliciously.(bizantine failures are not considered here)
\end{itemize}
using its own clock and the bounds of synchronous model, a process can infer if another process is crashed or just slow.
\subsection*{specification of Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-30 alle 18.25.47.png}
    \caption{Perfect Failure Detector properties}
\end{figure}
\subsection*{implementation of Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-30 alle 18.29.07.png}
    \caption{Perfect Failure Detector implementation}
\end{figure}

\subsubsection*{Initialization}
When the system starts (upon event $\langle p, \text{Init} \rangle$):
\begin{itemize}
    \item $\textit{alive} := \Pi$ --- Initialize the set of all processes
    \item $\textit{detected} := \emptyset$ --- Initialize the set of detected crashed processes as empty
    \item Set a periodic timer to trigger every $\Delta + \Phi$ time units
\end{itemize}
\subsubsection*{Main Event Handlers}
\begin{itemize}
    \item \textbf{Timer Event:} When the timer triggers (upon event $\langle p, \text{timeout} \rangle$):
    \begin{verbatim}
    for each process p in Pi do
      if p not in alive and p not in detected then
        detected := detected union {p};
        trigger <fd, Suspect | p>;
      send heartbeat message to p;
    alive := empty set;
    \end{verbatim}
    The process checks for processes that did not respond with a heartbeat and suspects them if they are not already suspected. It then sends heartbeat messages to all processes and resets the alive set.
    
    \item \textbf{Heartbeat Message Event:} When a heartbeat message is received from process $q$ (upon event $\langle p, \text{Heartbeat} | q \rangle$):
    \begin{verbatim}
    alive := alive union {q};

    \end{verbatim}
    The process that replied, they adds $q$ to the alive set. 
\end{itemize}
es:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4A77-8056-27-0.jpeg}
    \caption{Example of Perfect Failure Detector execution}
\end{figure}
\subsubsection*{correctness}
\begin{itemize}
    \item \textbf{Strong Completeness:} Eventually, every crashed process is permanently suspected by every correct process. This is ensured because crashed processes will not send heartbeat messages, leading to their suspicion.
    \item \textbf{Strong Accuracy:} No correct process is ever suspected. This is ensured because correct processes will always respond with heartbeat messages within the expected time frame.
\end{itemize}
if the timeout is very short, correct processes may be suspected due to network delays or processing time variations.
\newline
if the timeout is very long, crashed processes may not be suspected promptly, leading to delays in failure detection.
\newline
Thus, the choice of timeout value is crucial for the effectiveness of the Perfect Failure Detector.
\section{Eventually Perfect Failure Detector ($\Diamond P$)}
\subsection*{System model}
We consider a distributed system with the following assumptions.
\begin{itemize}
    \item \textbf{Partially Synchronous System:} The system is asynchronous but eventually becomes synchronous.
    \item \textbf{Crash Failures:} Processes can fail by \emph{crash}: a crashed process stops executing its algorithm forever, but they can't behave maliciously. (Byzantine failures are not considered here)
    \item \textbf{Perfect point to point links}
\end{itemize}
Crashed processes can be detected only after an unknown time $t$; before time $t$ there could be false suspicions (it behaves like an asynchronous system).

\subsection*{Basic Construction Rules}
An Eventually Perfect Failure Detector uses timeouts to suspect processes that did not send expected messages:
\begin{itemize}
    \item \textbf{Suspicion mechanism:} A suspect may be wrong. A process $p_i$ may suspect another one $p_j$ if the current timeout is too short.
    \item \textbf{Ready to change judgment:} $\Diamond P$ is ready to change its judgment as soon as it receives a message from $p_j$. In this case, the timeout value is updated to accommodate for longer delays.
    \item \textbf{Permanent suspicion:} If $p_j$ has actually crashed, $p_i$ does not change its judgment anymore.
\end{itemize}

The key difference from Perfect FD is that Eventually Perfect FD can make mistakes initially (false suspicions), but eventually stabilizes and behaves correctly once the system becomes synchronous and timeouts are adjusted appropriately.

\subsection*{specification of Eventually Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-30 alle 20.14.26.png}
    \caption{Eventually Perfect Failure Detector properties}
\end{figure}
\subsection*{implementation of Eventually Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-30 alle 20.20.51.png}
    \caption{Eventually Perfect Failure Detector implementation}
\end{figure}
\subsubsection*{Main Event Handlers}
\begin{itemize}
    \item \textbf{Timer Event:} When the timer triggers (upon event $\langle p, \text{timeout} \rangle$):
    \begin{verbatim}
    If there exists a process q in alive and q in suspected then
        delay= delay + d;
    for each process p in Pi do
      if p not in alive and p not in suspected then
        suspected := suspected union {p};
        trigger <fd, Suspect | p>;
        send heartbeat message to p;
      if p in alive and p in suspected then
        suspected := suspected \ {p};
        trigger <fd, Restore | p>;
        send heartbeat message to p;
    alive := empty set;
    start timer with delay;
    \end{verbatim}
    The process checks for processes that did not respond with a heartbeat and suspects them if they are not already suspected. If a previously suspected process responds, it is restored. The timeout delay is adjusted based on the suspicion status.
    \subsection*{example}
    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{imm/Immagine JPEG-4C4B-B34A-EA-0.jpeg}
        \caption{Example of Eventually Perfect Failure Detector execution}
    \end{figure}
\end{itemize}
\section{correctness}
\begin{itemize}
    \item \textbf{Strong Completeness:} If a process crashes, it will eventually be suspected by all correct processes. This is ensured because crashed processes will not send heartbeat messages, leading to their suspicion.
    \item \textbf{Eventual Strong Accuracy:} After some unknown time, no correct process is suspected. This is ensured because once the system becomes synchronous and timeouts are adjusted, correct processes will always respond with heartbeat messages within the expected time frame.
\end{itemize}

\chapter{Leadership Election (7-b)}
Leadership Election is a fundamental problem in distributed systems where processes need to agree on a single process to act as the leader or coordinator for certain tasks. The leader is responsible for making decisions, coordinating actions, and managing resources among the processes.
in the asynchronous system with crash failures,the system stabilizes after some unknown time t, and after t there is a correct process that is never suspected.
thus there are two opstions:
\begin{itemize}
    \item put the assumption on the system (Including links and processes)
    \item create a separate abstraction that encapsulates the assumption 
\end{itemize}
incapsulating the assumption in a separate abstraction is better because it allows to separate concerns, making the system more modular and easier to understand. While do all in a unique algorithm can lead to complex and hard to proof.
thus, we can use a single correct process that monitoring features of the system to elect a leader.
we can use several oracle(called leader election module) that provide information about the processes.
\section {Leader Election}
\subsection*{specification of Leader Election}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.33.44.png}
    \caption{Leader Election properties}
\end{figure}
\subsection*{implementation of Leader Election using Eventually Perfect Failure Detector}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.36.01.png}
    \caption{Leader Election implementation using Eventually Perfect Failure Detector}
\end{figure}
\subsubsection*{Main Event Handlers}
\begin{itemize}
    \item \textbf{Initialization Event:} When the system starts (upon event $\langle p, \text{Init} \rangle$):
    \begin{verbatim}
        leader != maxrank(Pi / suspected) - the process tha have the highest rank among those not suspected;
        leader := max(Pi/ suspected);
        trigger <le, NewLeader | leader>;
    \end{verbatim}
    The process selects the process with the highest rank among those not suspected as the leader and triggers a NewLeader event.
\end{itemize}
\subsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.44.40.png}
    \caption{Example of Leader Election execution}
\end{figure}
the correctness is guaranteed only if there is perfect failure detector. otherwise, there are two possibilities:
\begin{itemize}
    \item best scenario: suspect wrongly a crashed process, but the processes that continue to work are correct.
    \item worst scenario: FALSE POSITIVE, 2 processes could belive to have 2 different leaders.
\end{itemize}
\section{Eventual Leader Election}
\subsection*{specification of Eventual Leader Election}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 15.49.56.png}
    \caption{Eventual Leader Election properties}
\end{figure}

\subsubsection*{Key Properties and Behavior}
At first, every process may believe in a different leader, but after some unknown time $t$, all correct processes agree on the same correct leader.

\textbf{How it works:}
\begin{itemize}
    \item Every process decides a leader based on the information provided by the Eventually Perfect Failure Detector ($\Diamond P$).
    \item After time $t$ (when the system stabilizes), all correct processes agree on the same correct leader.
    \item We don't know when this time $t$ is, and during this initial period, crashed processes can be elected as leaders (false positives).
    \item Once the system stabilizes and elects a leader, the leader is not changed until it crashes. This stable leader is called \textbf{STABILIZED}.
\end{itemize}

\textbf{Important assumption:} There always exists at least one correct process.
\subsection*{implementation of Eventual Leader Election using Eventually Perfect Failure Detector}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.08.24.png}
    \caption{Eventual Leader Election implementation using Eventually Perfect Failure Detector}     
\end{figure}
Example:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.11.03.png}
    \caption{Example of Eventual Leader Election execution}
\end{figure}
\section{ eventual leader election with Crash-Recovery}
chrash-recovery model: processes can crash and later recover, resuming their operations from the state they had before crashing.
in this system the correct processes are p that never crash or that crash, recover and never crash again.
\subsection*{implementation of Eventual Leader Election in Crash-Recovery model}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.16.03.png}
    \caption{Eventual Leader Election implementation in Crash-Recovery model}
\end{figure}   
\subsubsection*{Initialization}
When the system starts (upon event $\langle p, \text{Init} \rangle$):
\begin{verbatim}
    epoch := 0; -- Initialize epoch counter(how many times the process has crashed and recovered)
    store(epoch); -- Store the epoch counter in stable storage
    candidates := empty set; -- Initialize the set of candidate leaders as empty
    trigger < \Omega , Recovery | >; -- Trigger a Recovery event
\end{verbatim}
\subsubsection*{trigger Recovery}
When a process recovers (upon event $\langle p, \text{Recovery} \rangle$):
\begin{verbatim}
    leader := maxrank(Pi) -- Select the process with the highest rank as the leader
    trigger <le, trust | leader>; -- Trigger a trust event with the selected leader
    delay := deltha; -- Initialize the delay for heartbeat messages
    retrieve(epoch); -- Retrieve the epoch counter from stable storage
    epoch := epoch + 1; -- Increment the epoch counter
    store(epoch); -- Store the updated epoch counter in stable storage
    forall q in Pi do
        send [HEARTBEAT, epoch] to q; -- Send heartbeat messages to all processes with the current epoch
    candidates := empty set; -- Reset the set of candidate leaders
    start timer with delay; -- Start the timer with the specified delay
\end{verbatim}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.22.32.png}
    \caption{Eventual Leader Election implementation in Crash-Recovery model}
\end{figure}  
\subsubsection*{ Timeout Event}
When the timer triggers (upon event $\langle p, \text{timeout} \rangle$):   
\begin{verbatim}
    elect new leader from candidates; 
    if the new leader != leader then. -- If a new leader is elected
        leader := new leader;
        trigger <le, trust | leader>;
    for all q in Pi do
        send [HEARTBEAT, epoch] to q; -- Send heartbeat messages to all processes with the current epoch
    candidates := empty set; -- Reset the set of candidate leaders
    start timer with delay; -- Start the timer with the specified delay
\end{verbatim}
\subsubsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.34.26.png}
    \caption{Example of Eventual Leader Election execution in Crash-Recovery model}
\end{figure}
the timer is incremented when a process receive a heartbeat from a process with higher epoch.(p1)
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.37.03.png}
    \caption{Example of Eventual Leader Election execution in Crash-Recovery model - part 2}    
\end{figure}
after the restore of p1, the epoch is incremented and p2 become the leader.

\chapter{ Broadcast Communication(9-10)}
Up to now, the comunication model used is between two processes (like clien-server enviroment).
In distributed systems, it is often necessary to communicate with multiple processes simultaneously. Broadcast communication is a method that allows a process to send a message to all other processes in the system.
\section{Best Effort Broadcast (BEB)}
Best Effort Broadcast (BEB) is a communication primitive that allows a process to send a message to all other processes in a distributed system with the following properties:
\begin{itemize}
    \item \textbf{Validity:} If a correct process broadcasts a message, then all correct processes eventually deliver that message.
    \item \textbf{No Duplication:} No message is delivered more than once to any process.
    \item \textbf{No Creation:} No message is delivered unless it was previously broadcast by some process.
\end{itemize}
\subsection*{specification of Best Effort Broadcast}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.45.59.png}
    \caption{Best Effort Broadcast properties}
\end{figure}
\subsection*{implementation of Best Effort Broadcast}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 16.47.13.png}
    \caption{Best Effort Broadcast implementation}
\end{figure}
\subsubsection*{correctness}
\begin{itemize}
    \item \textbf{Validity:} If a correct process broadcasts a message, it sends the message to all processes. In our model there are perfect point-to-point links, so all correct processes will eventually receive and deliver the message.
    \item \textbf{No Duplication:} Each process maintains a set of delivered messages. A message is only delivered if it has not been delivered before, ensuring no duplication.
    \item \textbf{No Creation:} perfect point-to-point links ensure that messages are only delivered if they were sent by some process. Since processes only deliver messages they receive, no message can be created out of thin air.
\end{itemize}
\section{ (Regular) Reliable Broadcast(RB)}
Reliable Broadcast (RB) is a communication primitive that extends Best Effort Broadcast by providing stronger guarantees in the presence of process failures. It ensures that messages are delivered reliably even if some processes crash.
the specification of RB are the same of BEB plus:
\begin{itemize}
    \item \textbf{Agreement:} If a correct process delivers a message, then all correct processes eventually deliver that message.
\end{itemize}
difference:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.21.12.png}
    \caption{Difference between Best Effort Broadcast and Reliable Broadcast}
\end{figure}
\section*{implementation of Reliable Broadcast IN Synchronous System }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.22.56.png}
    \caption{Reliable Broadcast implementation in Synchronous System}
\end{figure}
\subsubsection*{initialization}
When the system starts (upon event $\langle p, \text{Init} \rangle$):
\begin{verbatim}
    correct := Pi; -- Initialize the set of correct processes (all processes)
    from [p] := empty set[n]; -- Array to track messages received from each process
\end{verbatim}
\subsubsection*{deliver event}
When a message is delivered (upon event $\langle beb, \text{Deliver} | q, [DATA, s, m]\rangle$):
\begin{verbatim}
    if m not in from[q] then -- If the message has not been received from process q before
        from[q] := from[q] union {m}; -- Add the message to the set of messages received from process q
        trigger <rb, Deliver | s, m>; -- Trigger the delivery event for the reliable broadcast
        if s is not in correct then -- If the sender process s is not in the set of correct processes
            trigger <beb, Broadcast | [DATA, s, m]>; -- Trigger the delivery event for the reliable broadcast
\end{verbatim}
\subsubsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.34.59.png}
    \caption{Example of Reliable Broadcast execution in Asynchronous System}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.36.33.png}
    \caption{Example of Reliable Broadcast execution in Asynchronous System}
\end{figure}
\subsubsection*{Lazy Reliable Broadcast}
in the best scenario, the RB implementation can generate 1 BEB message per RB message .
\newline
in the worst scenario, the RB implementation can generate N-1 BEB messages per RB message.
\newline
if the failure detector is not perfect, the algorithm is not correct, because it may trigger unnecessary retransmissions or fail to detect crashed processes accurately.
\section{Reliable Broadcast (RB) in Asinchronous System}
\subsection*{implementation of Reliable Broadcast IN Asynchronous System }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.43.15.png}
    \caption{Reliable Broadcast implementation in Asynchronous System}
\end{figure}
in this case the best scenario is equal to worst scenario = N BEB messages per RB message, because every message is retransmitted by every process.
\section{ Uniform Reliable Broadcast (URB)}
Uniform Reliable Broadcast (URB) is a communication primitive that extends Reliable Broadcast by providing even stronger guarantees, particularly in the presence of process failures. It ensures that messages are delivered uniformly across all processes, meaning that if any process delivers a message, then all correct processes will eventually deliver that message.
thus, the specification of URB are the same of RB plus:
\begin{itemize}
    \item \textbf{Uniform Agreement:} If any process (correct or faulty) delivers a message, then all correct processes eventually deliver that message.
\end{itemize}
difference:
\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{imm/Screenshot 2025-12-01 alle 17.49.36.png}
    \caption{Difference between Reliable Broadcast and Uniform Reliable Broadcast}
\end{figure}
\subsection*{implementation of Uniform Reliable Broadcast IN Synchronous System }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-01 alle 17.50.30.png}
    \caption{Uniform Reliable Broadcast implementation in Synchronous System}
\end{figure}
\begin{verbatim}
    pending := empty set; -- Initialize the set of pending messages as empty
\end{verbatim}
when the message have to be broadcasted by URB, it is added to the pending set.

\begin{verbatim}
upon event <beb, Deliver | q, [DATA, s, m]> do
    ack[m] := ack[m] union {q}; -- Add the process q to the set of acknowledgments for message m
    if m not pending then -- If the message m is not in the pending set
        pending := pending union {m}; -- Add the message m to the pending set
        trigger <beb, broadcast | s, m>; 
\end{verbatim}

\subsection*{example}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.14.23.png}
    \caption{Example of Uniform Reliable Broadcast execution in Synchronous System}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.27.02.png}
    \caption{Example of Uniform Reliable Broadcast execution in Synchronous System - part 2}
\end{figure}    
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.27.19.png}
    \caption{Example of Uniform Reliable Broadcast execution in Synchronous System - part 3}
\end{figure}
\section{Implementation of Uniform Reliable Broadcast in Asynchronous Systems}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 13.31.39.png}
    \caption{Uniform Reliable Broadcast implementation in Asynchronous System}
\end{figure}
MANCA
\section{Probabilistic Broadcast (PB)}
Probabilistic Broadcast (PB) is a communication primitive that allows a process to send a message to all other processes in a distributed system with probabilistic guarantees. Unlike traditional broadcast methods that provide deterministic guarantees, PB relies on probabilistic techniques to ensure that messages are delivered to a large fraction of processes with high probability.
the ack mechanism used in RB is not scalable because it requires maintaining an acknowledgment set for each message, which can become large in systems with many processes. 
The probabilistic approach reduces the overhead associated with acknowledgments by allowing processes to make decisions based on probabilistic criteria rather than waiting for explicit acknowledgments from all processes.
\subsection*{specification of Probabilistic Broadcast}
the specification of PB includes the following properties:
\begin{itemize}
    \item \textbf{Probabilistic Validity:} If a correct process broadcasts a message, then with high probability, a large fraction of correct processes eventually deliver that message.
    \item \textbf{No Duplication:} No message is delivered more than once to any process.
    \item \textbf{No Creation:} No message is delivered unless it was previously broadcast by some process.
\end{itemize}
\subsubsection*{gossip Dissemination}
Gossip dissemination is a technique used in probabilistic broadcast to spread messages throughout a distributed system. In this approach, each process randomly selects a subset of other processes to which it forwards the message, creating a "gossip" effect that helps disseminate the message efficiently.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 14.38.18.png}
    \caption{Gossip Dissemination in Probabilistic Broadcast}
\end{figure}
\section*{implementation of Eager Probabilistic Broadcast}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-12-02 alle 14.38.58.png}
    \caption{Eager Probabilistic Broadcast implementation}
\end{figure}
\chapter{Consensus (11)}
\section{Consensus Problem}
The consensus problem in distributed systems involves a set of processes that must agree on a single value.
\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-25 alle 20.22.09.png}
    \caption{Consensus Problem}
\end{figure}
\section{consensus specification}
The consensus problem is defined by the following properties:
\begin{itemize}
    \item \textbf{Termination:} Every correct process eventually decides on a value.
    \item \textbf{Agreement:} No two correct processes decide on different values.
    \item \textbf{Validity:} If all correct processes propose the same value $v$, then any correct process that decides must decide $v$.
    \item \textbf{Integrity:} No correct process decides more than once.
\end{itemize}
\subsection*{Impossibility of Consensus in Asynchronous Systems with Failures}
In an asynchronous distributed system where processes can fail by crashing, it is impossible to design a deterministic consensus algorithm that satisfies all the properties of termination, agreement, validity, and integrity.
\newline
This result is known as the FLP impossibility theorem, named after Fischer, Lynch, and Paterson.The key intuition behind the FLP impossibility result is that in an asynchronous system, there is no upper bound on message delivery times or process execution speeds.
\section{Consensus Implementation in Synchronous Systems}
\subsection*{Flooding-based Consensus Algorithm}
In a synchronous system, we can implement a consensus algorithm using a flooding-based approach.All processes exchange their proposed values in rounds, and after a fixed number of rounds, they decide on a value based on the received proposals.
the rounds are fundamental because they provide a structured way for processes to communicate and ensure that all correct processes have the opportunity to share their proposed values before making a decision.(in this way we are sure that there aren't lost values)
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 20.43.55.png}
    \caption{Flooding-based Consensus Algorithm}
\end{figure}

\section{Algorithm Description}

\subsection{Initialization}
When the system starts (upon event $\langle c, \text{Init} \rangle$):
\begin{itemize}
    \item $\textit{correct} := \Pi$ --- Initialize the set of correct processes (all processes)
    \item $\textit{round} := 1$ --- Start from round 1
    \item $\textit{decision} := \bot$ --- The decision is still empty ($\bot$ means ``not decided'')
    \item $\textit{receivedFrom}[r] := [\emptyset]^N$ --- Array tracking from which processes we have received messages for each round
    \item $\textit{proposals}[r] := [\emptyset]^N$ --- Array tracking the proposals received for each round
\end{itemize}

\subsection{Main Event Handlers}

\subsubsection{Propose Event}
When a process proposes a value:
\begin{verbatim}
upon event <c, Propose | v> do
  proposals[1] := proposals[1] union {v};
  trigger <beb, Broadcast | [PROPOSAL, 1, proposals[1]]>;
\end{verbatim}
The process adds its initial value to the proposals of round 1 and broadcasts it to all processes.

\subsubsection{Crash Event}
When the Failure Detector detects a crash:
\begin{verbatim}
upon event <P, Crash | p> do
  correct := correct \ {p};
\end{verbatim}
Removes the process from the set of correct processes.

\subsubsection{Deliver Event}
When a PROPOSAL is received:
\begin{verbatim}
upon event <beb, Deliver | p, [PROPOSAL, r, ps]> do
  receivedFrom[r] := receivedFrom[r] union {p};
  proposals[r] := proposals[r] union ps;
\end{verbatim}
Updates the list of processes from which messages have been received and merges the received proposals.

\subsection{Decision Logic}
The crucial logic for deciding:
\begin{verbatim}
upon correct subseteq receivedFrom[round] AND decision = bottom do
  if receivedFrom[round] = receivedFrom[round-1] then
    decision := min(proposals[round]);
    trigger <beb, Broadcast | [DECIDED, decision]>;
    trigger <c, Decide | decision>;
  else
    round := round + 1;
    trigger <beb, Broadcast | [PROPOSAL, round, proposals[round-1]]>;
\end{verbatim}

This is the most important part:
\begin{itemize}
    \item \textbf{Waiting condition:} The process waits until it has received messages from all correct processes ($\textit{correct} \subseteq \textit{receivedFrom}[\textit{round}]$)
    \item \textbf{Stability:} If the set of processes from which messages were received in this round is the same as in the previous round (no new crashes), we can trust the data
    \item \textbf{Decision:} Chooses the minimum value among the received proposals (deterministic function common to all processes, can be replaced with other functions)
    \item \textbf{Decision broadcast:} Communicates the decided value to all other processes
    \item \textbf{Else:} If the set changes (new crash detected), increment the round and continue
\end{itemize}

\subsection{Receiving DECIDED}
\begin{verbatim}
upon event <beb, Deliver | p, [DECIDED, v]> 
  such that p in correct AND decision = bottom do
  decision := v;
  trigger <beb, Broadcast | [DECIDED, decision]>;
  trigger <c, Decide | decision>;
\end{verbatim}
If a correct process communicates the decided value and the receiving process has not yet decided, it decides this value.

\subsection{Practical Example}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 21.04.25.png}
    \caption{Example of Consensus Algorithm Execution}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 21.10.31.png}
    \caption{P3 decide the min value after the decision of p1}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{imm/Screenshot 2025-11-25 alle 21.08.58.png}
    \caption{p2 is the only one thet can decide but crash before the broadcast of the value, so P1 and P3 go to the next round and decide an other value}
\end{figure}

\section{Uniform Consensus Specification}
The difference between uniform consensus and (non-uniform) consensus is that uniform consensus requires \textbf{Uniform Agreement}: no two processes (correct or faulty) can decide different values. In standard consensus, only correct processes are required to agree, meaning a faulty process may decide a different value before crashing.
in the algorithm the decision is choseen at the round N, (at the end) and the set of proposals is the same for all processes, so also faulty processes decide the same value of correct processes.
\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-25 alle 22.55.28.png}
    \caption{Uniform Consensus properties}
\end{figure}
\subsubsection*{Example}
\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{imm/Screenshot 2025-11-25 alle 22.59.09.png}
    \caption{at the round 3 there is a decision, that is 5 becaus when start a new round the receivedFrom set is = 0}
\end{figure}
\chapter{Paxos (12)}
Paxos is a consensus algorithm designed for asynchronous distributed systems with crash failures.
The safety is always guaranteed, while the liveness is guaranteed only under some conditions (like eventual message delivery and a majority of correct processes).

\section{Assumptions}
\begin{itemize}
    \item \textbf{Agents:} Operate at arbitrary speed, may fail by stopping (and may restart).
    \begin{itemize}
        \item \textbf{Observation:} Since all agents may fail after a value is chosen and then restart, a solution is impossible unless some information can be remembered by an agent that has failed and restarted.
    \end{itemize}
    \item \textbf{Messages:} Can take arbitrarily long to be delivered, can be duplicated, and can be lost, but they are not corrupted.
\end{itemize}
\section{Actors}
Paxos involves three types of actors:
\begin{itemize}
    \item \textbf{Proposers:} Propose values to be agreed upon.
    \item \textbf{Acceptors:} Act as the voting body that decides which value to accept.
    \item \textbf{Learners:} Learn the chosen value once consensus is reached.
\end{itemize}

\subsection*{first problem}
if there isa asingle acceptor, and it crash after accepting a value, the system cannot make progress.

\chapter{Total Order Broadcast}
Total Order Broadcast (TOB) is a fundamental communication primitive in distributed systems that ensures all processes deliver messages in the same order.

\section{System model}
We consider a distributed system with the following assumptions.
\begin{itemize}
    \item \textbf{Processes:}
    \begin{itemize}
        \item There is a static set of processes $p_1, \dots, p_n$.
        \item Processes can fail by \emph{crash}: a crashed process stops executing its algorithm forever, but they can't behave maliciously.(bizantine failures are not considered here)
        \item A process that never crashes is called a \emph{correct} process.
        \end{itemize}
    \item \textbf{Communication:}Channels between correct processes are \emph{perfect}: messages are not lost, not duplicated, and no fake messages are created.
    \item \textbf{Asynchronous:} there is no known upper bound on message transmission time or processing time.
\end{itemize}

\section{Total Order specification}
TO (Total Order) is composed by 4 specifications:
\begin{itemize}
    \item \textbf{Validity:} If a correct process broadcasts a message $m$, then it eventually delivers $m$.
    \item \textbf{Uniform Agreement:} If a process delivers a message $m$, then all correct processes eventually deliver $m$.
    \item \textbf{Uniform Integrity:} For any message $m$, every process delivers $m$ at most once, and only if $m$ was previously broadcast by its sender.
    \item \textbf{Uniform Total Order:} If two processes $p_i$ and $p_j$ deliver two messages $m$ and $m'$, then $p_i$ delivers $m$ before $m'$ if and only if $p_j$ delivers $m$ before $m'$.
\end{itemize}
Validity parla di consegna assicurata per messaggi validi.
\newline
Uniform Agreement parla di accordo sull'insieme dei messaggi consegnati.
\newline
Uniform Integrity parla di evitare duplicati e messaggi inventati.
\newline
Uniform Total Order parla di accordo sull'ordine esatto di consegna.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 18.09.55.png}
    \caption{Total Order Broadcast properties}
\end{figure}
A Uniform properties is stronger than a non-uniform one because it applies to all processes, not just correct ones.

\section {Non-Uniform Validity-Uniform Integrity}
Such that our system have perfect channel and chra failures, the properties satisfied are:
\newline
NUV (Non-Uniform Validity): If a correct process broadcasts a message $m$, then it eventually delivers $m$.
\newline
UI (Uniform Integrity): For any message $m$, every process delivers $m$ at most once, and only if $m$ was previously broadcast by its sender.
\newline
the properties that are not satisfied are: Agreement and Total Order.
\subsubsection*{Agreement property}
\begin{itemize}
    \item \textbf{Non-Uniform Agreement:} If a CORRECT process delivers a message $m$, then all correct processes eventually deliver $m$.
    \item \textbf{Uniform Agreement:} If a process delivers a message $m$, then all correct processes eventually deliver $m$.
    \newline
    \newline
    The difference is that in Uniform Agreement, the process delivering $m$ can be faulty.The correct processes deliver the same set of messages, while faulty processes may deliver a different set of messages or none at all.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 18.41.44.png}
        \caption{Non-Uniform Agreement vs Uniform Agreement}
    \end{figure}
    UA: If P3 (faulty process) delivers m2, then P1 and P2 (correct processes) must also deliver m2.
    \newline
    NUA: If P3 (faulty process) delivers m5, it does not imply that P1 and P2 (correct processes) must also deliver m5.
\end{itemize}
\subsubsection*{Total Order property}
\begin{itemize}
    \item \textbf{Strong Uniform Total Order:} if some process deliver message m before m', then a process deliver m' only after m.
    \item \textbf{Weak Uniform Total Order:} If two processes $p_i$ and $p_j$ deliver two messages $m$ and $m'$, then $p_i$ delivers $m$ before $m'$ if and only if $p_j$ delivers $m$ before $m'$.
\end{itemize}
    The difference is that in SUTO, all processes must deliver the same set of messages in the same order, while in WUTO, processes may deliver different sets of messages, but the relative order of any two messages is consistent across processes that deliver both messages.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 18.48.48.png}
        \caption{Strong Uniform Total Order vs Weak Uniform Total Order}
    \end{figure}
    SUTO: if process p3,delivers message m4 before m5, then process p4 must also deliver m4 before m5.
    \newline
    WUTO: Each process may deliver a different set of messages, but the relative order between any two messages is always the same for processes that deliver both messages.

\begin{itemize}
    \item \textbf{Strong non-Uniform Total Order:} if some CORRECT process deliver message m before m', then a CORRECT process deliver m' only after m.
    \item \textbf{Weak non-Uniform Total Order:} If two CORRECT processes $p_i$ and $p_j$ deliver two messages $m$ and $m'$, then $p_i$ delivers $m$ before $m'$ if and only if $p_j$ delivers $m$ before $m'$.
\end{itemize}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{imm/Screenshot 2025-11-25 alle 19.02.37.png}
        \caption{}
    \end{figure}
    Strong assumptions is more restrictive than weak assumptions (SUTO=>WUTO- SNUTO=>WNUTO).
\section{Examples of Total Order Broadcast Variants}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.06.png}
    \hfill
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.15.png}
    \caption*{UA + SUTO: All processes deliver the same set of messages in the same order. \newline NUA + SUTO: Only correct processes deliver the same set/order; faulty process may miss messages ($m_4$, $m_5$ missing).}
    \vspace{1em}
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.26.png}
    \hfill
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.40.png}
    \caption*{UA + WUTO: All processes deliver the same set with consistent relative order. \newline NUA + WUTO: Only correct processes deliver the same set with consistent relative order.\newline}
    \vspace{1em}
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.48.png}
    \hfill
    \includegraphics[width=0.42\textwidth]{imm/Screenshot 2025-11-25 alle 19.15.56.png}
    \caption*{UA + WNUTO: Correct processes deliver the same set with consistent relative order; faulty process behavior is undefined. \newline NUA + WNUTO: Correct processes deliver the same set with consistent relative order; $m_5$ missing from some processes.}
\end{figure}
\end{document}